{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1KbrN9Li5i8"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSm_UBPsLzq_",
        "outputId": "39d8ba22-4808-4519-d1ce-388cb794e306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorboardX in /home/noam/.local/lib/python3.8/site-packages (2.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /home/noam/.local/lib/python3.8/site-packages (from tensorboardX) (3.20.3)\n",
            "Requirement already satisfied: packaging in /home/noam/.local/lib/python3.8/site-packages (from tensorboardX) (23.0)\n",
            "Requirement already satisfied: numpy in /home/noam/.local/lib/python3.8/site-packages (from tensorboardX) (1.24.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pyglet==1.5.1 in /home/noam/.local/lib/python3.8/site-packages (1.5.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchsummary in /home/noam/.local/lib/python3.8/site-packages (1.5.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: optuna in /home/noam/.local/lib/python3.8/site-packages (3.1.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/noam/.local/lib/python3.8/site-packages (from optuna) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/noam/.local/lib/python3.8/site-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: colorlog in /home/noam/.local/lib/python3.8/site-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: tqdm in /home/noam/.local/lib/python3.8/site-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /home/noam/.local/lib/python3.8/site-packages (from optuna) (1.10.2)\n",
            "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna) (5.3.1)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /home/noam/.local/lib/python3.8/site-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: numpy in /home/noam/.local/lib/python3.8/site-packages (from optuna) (1.24.2)\n",
            "Requirement already satisfied: importlib-resources in /home/noam/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (5.12.0)\n",
            "Requirement already satisfied: Mako in /home/noam/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: importlib-metadata in /home/noam/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /home/noam/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/noam/.local/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/noam/.local/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/noam/.local/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: optuna-dashboard in /home/noam/.local/lib/python3.8/site-packages (0.9.0)\n",
            "Requirement already satisfied: packaging in /home/noam/.local/lib/python3.8/site-packages (from optuna-dashboard) (23.0)\n",
            "Requirement already satisfied: optuna>=2.4.0 in /home/noam/.local/lib/python3.8/site-packages (from optuna-dashboard) (3.1.0)\n",
            "Requirement already satisfied: bottle in /home/noam/.local/lib/python3.8/site-packages (from optuna-dashboard) (0.12.25)\n",
            "Requirement already satisfied: scikit-learn in /home/noam/.local/lib/python3.8/site-packages (from optuna-dashboard) (1.2.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /home/noam/.local/lib/python3.8/site-packages (from optuna>=2.4.0->optuna-dashboard) (1.10.2)\n",
            "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna>=2.4.0->optuna-dashboard) (5.3.1)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /home/noam/.local/lib/python3.8/site-packages (from optuna>=2.4.0->optuna-dashboard) (0.9.1)\n",
            "Requirement already satisfied: colorlog in /home/noam/.local/lib/python3.8/site-packages (from optuna>=2.4.0->optuna-dashboard) (6.7.0)\n",
            "Requirement already satisfied: numpy in /home/noam/.local/lib/python3.8/site-packages (from optuna>=2.4.0->optuna-dashboard) (1.24.2)\n",
            "Requirement already satisfied: tqdm in /home/noam/.local/lib/python3.8/site-packages (from optuna>=2.4.0->optuna-dashboard) (4.65.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/noam/.local/lib/python3.8/site-packages (from optuna>=2.4.0->optuna-dashboard) (2.0.8)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/noam/.local/lib/python3.8/site-packages (from scikit-learn->optuna-dashboard) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/noam/.local/lib/python3.8/site-packages (from scikit-learn->optuna-dashboard) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/noam/.local/lib/python3.8/site-packages (from scikit-learn->optuna-dashboard) (1.10.1)\n",
            "Requirement already satisfied: importlib-resources in /home/noam/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (5.12.0)\n",
            "Requirement already satisfied: importlib-metadata in /home/noam/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (4.13.0)\n",
            "Requirement already satisfied: Mako in /home/noam/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /home/noam/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/noam/.local/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna>=2.4.0->optuna-dashboard) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/noam/.local/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/noam/.local/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (2.1.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX\n",
        "!pip install pyglet==1.5.1\n",
        "!pip install torchsummary\n",
        "!pip install optuna\n",
        "!pip install optuna-dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbigCoubxceQ",
        "outputId": "da980382-8858-44f8-e876-39872e99ac1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: setuptools==65.5.1 in /home/noam/.local/lib/python3.8/site-packages (65.5.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: gym==0.21.0 in /home/noam/.local/lib/python3.8/site-packages (0.21.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/noam/.local/lib/python3.8/site-packages (from gym==0.21.0) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /home/noam/.local/lib/python3.8/site-packages (from gym==0.21.0) (1.24.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: stable-baselines3[extra] in /home/noam/.local/lib/python3.8/site-packages (1.7.0)\n",
            "Requirement already satisfied: importlib-metadata~=4.13 in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.13.0)\n",
            "Requirement already satisfied: torch>=1.11 in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.0.0)\n",
            "Requirement already satisfied: gym==0.21 in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.21.0)\n",
            "Requirement already satisfied: cloudpickle in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: numpy in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.24.2)\n",
            "Requirement already satisfied: matplotlib in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: pandas in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.5.3)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.12.1)\n",
            "Requirement already satisfied: rich in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (13.3.3)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.4.2)\n",
            "Requirement already satisfied: tqdm in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.65.0)\n",
            "Requirement already satisfied: opencv-python in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.7.0.72)\n",
            "Requirement already satisfied: psutil in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (5.9.4)\n",
            "Requirement already satisfied: ale-py==0.7.4 in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.7.4)\n",
            "Requirement already satisfied: pillow in /home/noam/.local/lib/python3.8/site-packages (from stable-baselines3[extra]) (9.5.0)\n",
            "Requirement already satisfied: importlib-resources in /home/noam/.local/lib/python3.8/site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.12.0)\n",
            "Requirement already satisfied: click in /home/noam/.local/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.1.3)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.22.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /home/noam/.local/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/noam/.local/lib/python3.8/site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.34.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.17.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.53.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/noam/.local/lib/python3.8/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (65.5.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.7.4.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.4.0.1)\n",
            "Requirement already satisfied: filelock in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (3.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.11->stable-baselines3[extra]) (2.10.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.7.101)\n",
            "Requirement already satisfied: networkx in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (3.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.7.99)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (10.2.10.91)\n",
            "Requirement already satisfied: sympy in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (1.11.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.7.91)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/noam/.local/lib/python3.8/site-packages (from torch>=1.11->stable-baselines3[extra]) (2.14.3)\n",
            "Requirement already satisfied: cmake in /home/noam/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3[extra]) (3.26.1)\n",
            "Requirement already satisfied: lit in /home/noam/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3[extra]) (16.0.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/noam/.local/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/noam/.local/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/noam/.local/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/noam/.local/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/noam/.local/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/noam/.local/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/noam/.local/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/noam/.local/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/noam/.local/lib/python3.8/site-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/noam/.local/lib/python3.8/site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.14.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/noam/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/noam/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/noam/.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/noam/.local/lib/python3.8/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/noam/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.2)\n",
            "Requirement already satisfied: libtorrent in /home/noam/.local/lib/python3.8/site-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/noam/.local/lib/python3.8/site-packages (from sympy->torch>=1.11->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install setuptools==65.5.1\n",
        "!pip install gym==0.21.0\n",
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc0SC4CrMXSk",
        "outputId": "72a96155-d3d3-4f64-e143-6913e97a2d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pyvirtualdisplay in /home/noam/.local/lib/python3.8/site-packages (3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !sudo apt-get install -y xvfb\n",
        "!pip install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Jul 17 15:44:13 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 530.50                 Driver Version: 531.79       CUDA Version: 12.1     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1060 6GB     On | 00000000:01:00.0  On |                  N/A |\n",
            "|  0%   47C    P8                9W / 200W|    310MiB /  6144MiB |      8%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kImBr6NFjKIY"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1NHYcVNMQaW",
        "outputId": "48e3c777-fc26-4b63-eba1-6e11e47aa30c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fbf8c6940d0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1024, 768))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Get the absolute path to the parent directory of gym-tetris\n",
        "gym_tetris_parent_path = os.path.abspath(os.path.join('..', 'gym-tetris'))\n",
        "\n",
        "# Append the path to the sys.path\n",
        "sys.path.append(gym_tetris_parent_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TidRAkGEU0Wl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.1.0) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import time\n",
        "from distutils.util import strtobool\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from stable_baselines3.common.buffers import ReplayBuffer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_tetris\n",
        "from gym_tetris.actions import SIMPLE_MOVEMENT\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "H-rvKojYAuK3"
      },
      "outputs": [],
      "source": [
        "# class QNetwork(nn.Module):\n",
        "#     def __init__(self, actions_num):\n",
        "#         super().__init__()\n",
        "#         self.network =  nn.Sequential(\n",
        "#             # (1, 84, 84)\n",
        "#             nn.Conv2d(1, 32, 8, stride=4),\n",
        "#             nn.ReLU(),\n",
        "#             # (32, 20, 20)\n",
        "#             nn.Conv2d(32, 64, 4, stride=2),\n",
        "#             nn.ReLU(),\n",
        "#             # (64, 9, 9)\n",
        "#             nn.Conv2d(64, 64, 3, stride=1),\n",
        "#             nn.ReLU(),\n",
        "#             # (64, 7, 7)\n",
        "#             nn.Flatten(),\n",
        "#             # 3136\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.Linear(3136, 512),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(512, actions_num),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.network(x / 255.0)\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, actions_num, frame_stack=1):\n",
        "        super().__init__()\n",
        "        self.network =  nn.Sequential(\n",
        "            # (frame_stack, 84, 84)\n",
        "            nn.Conv2d(frame_stack, 32, 8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            # (32, 20, 20)\n",
        "            nn.Conv2d(32, 64, 4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            # (64, 9, 9)\n",
        "            nn.Conv2d(64, 64, 3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            # (64, 7, 7)\n",
        "            nn.Flatten(),\n",
        "            # 3136\n",
        "            # nn.Dropout(0.2),\n",
        "            nn.Linear(3136, 512),\n",
        "            # nn.Dropout(0.2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, actions_num),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.flatten()[0])\n",
        "        return self.network(x / 255.0)\n",
        "\n",
        "\n",
        "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
        "    slope = (end_e - start_e) / duration\n",
        "    return max(slope * t + start_e, end_e)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8KbPbg5G8_sO"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from collections import deque\n",
        "# class MaxAndSkipEnv(gym.Wrapper):\n",
        "#     def __init__(self, env=None, skip=4):\n",
        "#         super(MaxAndSkipEnv, self).__init__(env)\n",
        "#         self._obs_buffer = deque(maxlen=2)\n",
        "#         self._skip = skip\n",
        "\n",
        "#     def step(self, action):\n",
        "#         total_reward = 0.0\n",
        "#         done = None\n",
        "#         for _ in range(self._skip):\n",
        "#             obs, reward, done, info = self.env.step(action)\n",
        "#             self._obs_buffer.append(obs)\n",
        "#             total_reward += reward\n",
        "#             if done:\n",
        "#                 break\n",
        "#         max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
        "#         return max_frame, total_reward, done, info\n",
        "    \n",
        "#     def reset(self):\n",
        "#         self._obs_buffer.clear()\n",
        "#         obs = self.env.reset()\n",
        "#         self._obs_buffer.append(obs)\n",
        "#         return obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FrameSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None, skip=4, only_first=False):\n",
        "        super(FrameSkipEnv, self).__init__(env)\n",
        "        self._skip = skip\n",
        "        self._only_first = only_first\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for i in range(self._skip):\n",
        "            # Only do the action on the first frame (action 0 is always NOOP)\n",
        "            real_action = 0 if (self._only_first and i > 0) else action\n",
        "            obs, reward, done, info = self.env.step(real_action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info\n",
        "    \n",
        "    def reset(self):\n",
        "        obs = self.env.reset()\n",
        "        return obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZCEBIoO8pd9D"
      },
      "outputs": [],
      "source": [
        "BOX = 47, 95, 209, 176\n",
        "# Making an environment\n",
        "def get_env(env_id, seed, capture_video, run_name, video_freq=100, frame_stack=4):\n",
        "    env = gym_tetris.make(env_id)\n",
        "    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "    if capture_video:\n",
        "        env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\", episode_trigger=lambda ep_num: ep_num % video_freq == 0)\n",
        "    \n",
        "    crop = lambda obs : obs[BOX[0]:BOX[2], BOX[1]:BOX[3], :]\n",
        "    env = gym.wrappers.TransformObservation(env, crop)\n",
        "    env = gym.wrappers.ResizeObservation(env, (84, 84))\n",
        "    env = gym.wrappers.GrayScaleObservation(env)\n",
        "\n",
        "    env = FrameSkipEnv(env, skip=16, only_first=True)\n",
        "    env = gym.wrappers.FrameStack(env, frame_stack)\n",
        "    env = FrameSkipEnv(env, skip=2, only_first=False)\n",
        "\n",
        "    env.seed(seed)\n",
        "    env.action_space.seed(seed)\n",
        "    env.observation_space.seed(seed)\n",
        "    return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "def evaluate(\n",
        "    model: torch.nn.Module,\n",
        "    env_id: str,\n",
        "    eval_episodes: int,\n",
        "    run_name: str,\n",
        "    seed: int,\n",
        "    device: torch.device = torch.device(\"cpu\"),\n",
        "    capture_video: bool = True,\n",
        "    video_frequency: int = 1,\n",
        "    frame_stack: int = 1\n",
        "):\n",
        "    env = get_env(env_id, seed, capture_video, run_name, video_frequency, frame_stack) \n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    scores = []\n",
        "    for _ in range(eval_episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            input = np.expand_dims(np.array(obs), axis=0)\n",
        "            q_values = model(torch.Tensor(input).to(device))\n",
        "            action = int(torch.argmax(q_values))\n",
        "            obs, _, done, info = env.step(action)\n",
        "        \n",
        "        print(f\"eval_episode={len(scores)}, score={info.get('score')}, episodic_return={info.get('episode')['r']}\")\n",
        "        scores.append(info.get(\"score\"))\n",
        "\n",
        "    env.close()\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single env training without optuna - for simplicity\n",
        "def train(args):\n",
        "    run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
        "    prefix = \"\"\n",
        "    \n",
        "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
        "    writer.add_text(\n",
        "        \"hyperparameters\",\n",
        "        \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
        "    )\n",
        "\n",
        "    # TRY NOT TO MODIFY: seeding\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.backends.cudnn.deterministic = args.torch_deterministic\n",
        "\n",
        "    device_name = \"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\"\n",
        "    device_name = \"mps\" if torch.backends.mps.is_available() and args.mps else device_name\n",
        "    device = torch.device(device_name)\n",
        "\n",
        "    print(\"device_name:\", device_name)\n",
        "\n",
        "    # env setup\n",
        "    env = get_env(args.env_id, args.seed, args.capture_video, run_name, args.video_frequency, args.frame_stack)\n",
        "    assert isinstance(env.action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n",
        "\n",
        "    q_network = QNetwork(env.action_space.n, args.frame_stack).to(device)\n",
        "    optimizer = optim.Adam(q_network.parameters(), lr=args.learning_rate)\n",
        "    target_network = QNetwork(env.action_space.n, args.frame_stack).to(device)\n",
        "    target_network.load_state_dict(q_network.state_dict())\n",
        "\n",
        "    summary(q_network, input_size=(args.frame_stack, 84, 84), batch_size=args.batch_size, device=device_name)\n",
        "\n",
        "    rb = ReplayBuffer(\n",
        "        args.buffer_size,\n",
        "        env.observation_space,\n",
        "        env.action_space,\n",
        "        device,\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Tracks the number of pieces we have played\n",
        "    piece_count = 0\n",
        "    board_height = None\n",
        "    explore = True\n",
        "    info = None\n",
        "\n",
        "    episode_cnt = 0\n",
        "\n",
        "    input_fps = 2\n",
        "    input_size = (84,84)\n",
        "    if args.capture_inputs_video:\n",
        "        out = cv2.VideoWriter(f'/model_input_videos/episode0.mp4', cv2.VideoWriter_fourcc(*'mp4v'), input_fps, (input_size[1], input_size[0]), False)\n",
        "\n",
        "    # TRY NOT TO MODIFY: start the game\n",
        "    obs = env.reset()\n",
        "    for global_step in range(args.total_timesteps):\n",
        "        \n",
        "        if args.capture_inputs_video and (episode_cnt % args.video_frequency == 0):\n",
        "            img = np.array(obs).astype('uint8')\n",
        "            if args.frame_stack > 1:\n",
        "                img = img[0]\n",
        "            out.write(img)\n",
        "        \n",
        "        # If a new piece has been generated, decide wether we will explore or exploit for this piece\n",
        "        if (info is not None) and (piece_count != info.get(\"piece_count\")):\n",
        "            piece_count = info.get(\"piece_count\")\n",
        "            epsilon = linear_schedule(args.start_e, args.end_e, args.exploration_fraction * args.total_timesteps, global_step)\n",
        "            explore = (random.random() < epsilon)\n",
        "\n",
        "        if explore:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            input = np.expand_dims(np.array(obs), axis=0)\n",
        "            input = torch.Tensor(input).to(device)\n",
        "            q_values = q_network(input)\n",
        "            action = int(torch.argmax(q_values))\n",
        "\n",
        "        # Play a step with the given action\n",
        "        next_obs, reward, done, info = env.step(action)\n",
        "\n",
        "        if not done:\n",
        "            # Add observation to replay buffer\n",
        "            rb.add(obs, next_obs, np.array([action]), [reward], [done], [info])\n",
        "            obs = next_obs\n",
        "        else:\n",
        "            print(f\"Episode {episode_cnt} completed: {prefix}global_step={global_step},\\tepisodic_return={info.get('episode')['r']:.1f},\\tscore={info.get('score')}\")\n",
        "            writer.add_scalar(\"charts/episodic_return\", info.get(\"episode\")[\"r\"], global_step)\n",
        "            writer.add_scalar(\"charts/episodic_length\", info.get(\"episode\")[\"l\"], global_step)\n",
        "            writer.add_scalar(\"charts/epsilon\", epsilon, global_step)\n",
        "            writer.add_scalar(\"charts/score\", info.get(\"score\"), global_step)\n",
        "\n",
        "            obs = env.reset()\n",
        "            episode_cnt += 1\n",
        "\n",
        "            if args.capture_inputs_video:\n",
        "                if episode_cnt % args.video_frequency == 0:\n",
        "                    out = cv2.VideoWriter(f'/model_input_videos/episode{episode_cnt}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), input_fps, (input_size[1], input_size[0]), False)\n",
        "                else:\n",
        "                    out = None\n",
        "\n",
        "        # Training Logic\n",
        "        if global_step > args.learning_starts:\n",
        "            if global_step % args.train_frequency == 0:\n",
        "                data = rb.sample(args.batch_size)\n",
        "                with torch.no_grad():\n",
        "                    target_max, _ = target_network(data.next_observations).max(dim=1)\n",
        "                    td_target = data.rewards.flatten() + args.gamma * target_max * (1 - data.dones.flatten())\n",
        "                old_val = q_network(data.observations).gather(1, data.actions).squeeze()\n",
        "                # loss = F.mse_loss(td_target, old_val)\n",
        "                loss = F.mse_loss(old_val, td_target)\n",
        "\n",
        "                if global_step % 100 == 0:\n",
        "                    writer.add_scalar(\"losses/td_loss\", loss, global_step)\n",
        "                    writer.add_scalar(\"losses/q_values\", old_val.mean().item(), global_step)\n",
        "                    writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
        "\n",
        "                # optimize the model\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # update target network\n",
        "            if global_step % args.target_network_frequency == 0:\n",
        "                for target_network_param, q_network_param in zip(target_network.parameters(), q_network.parameters()):\n",
        "                    target_network_param.data.copy_(\n",
        "                        args.tau * q_network_param.data + (1.0 - args.tau) * target_network_param.data\n",
        "                    )\n",
        "\n",
        "            if global_step % args.backup_frequency == 0:\n",
        "                model_backup_path = f\"runs/{run_name}/{args.exp_name}.backup\"\n",
        "                torch.save(q_network.state_dict(), model_backup_path)\n",
        "\n",
        "    if args.save_model:\n",
        "        model_path = f\"runs/{run_name}/{args.exp_name}.cleanrl_model\"\n",
        "        torch.save(q_network.state_dict(), model_path)\n",
        "        print(f\"{prefix}model saved to {model_path}\")\n",
        "\n",
        "        scores = evaluate(\n",
        "            q_network,\n",
        "            args.env_id,\n",
        "            args.eval_episodes,\n",
        "            run_name=f\"{run_name}-eval\",\n",
        "            seed=args.seed,\n",
        "            device=device,\n",
        "            capture_video=args.capture_video,\n",
        "            frame_stack=args.frame_stack\n",
        "        )\n",
        "\n",
        "        print(\"Eval Scores:\", scores)\n",
        "        \n",
        "    env.close()\n",
        "    writer.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jhHGXzJGi-yI"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "a74aYTyfXD3A"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        # Settings\n",
        "        self.exp_name = \"Tetris_DQN\"\n",
        "        self.torch_deterministic = True\n",
        "        self.cuda = True\n",
        "        self.mps = False\n",
        "        self.capture_video = True\n",
        "        self.capture_inputs_video = True\n",
        "        self.save_model = True\n",
        "        self.eval_episodes = 1\n",
        "        self.video_frequency = 50\n",
        "        self.backup_frequency = 10000\n",
        "\n",
        "        # Hyper-Parameters\n",
        "        self.env_id = \"TetrisA-v5\"\n",
        "        self.frame_stack = 4\n",
        "        self.seed = 2\n",
        "        self.total_timesteps = 1_000_000\n",
        "        self.learning_rate = 1e-4\n",
        "        self.buffer_size = 50_000\n",
        "        self.gamma = 0.99\n",
        "        self.tau = 0.999\n",
        "        self.target_network_frequency = 2000\n",
        "        self.batch_size = 32\n",
        "        self.start_e = 1\n",
        "        self.end_e = 0.05\n",
        "        self.exploration_fraction = 0.2\n",
        "        self.learning_starts = 40_000\n",
        "        self.train_frequency = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "74u8GL2dfD2F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'images/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r runs/* videos/* images/* episode*.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm_lId5hUjDm",
        "outputId": "c886e297-b83f-465d-bba7-06f47371cb71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device_name: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [32, 32, 20, 20]           8,224\n",
            "              ReLU-2           [32, 32, 20, 20]               0\n",
            "            Conv2d-3             [32, 64, 9, 9]          32,832\n",
            "              ReLU-4             [32, 64, 9, 9]               0\n",
            "            Conv2d-5             [32, 64, 7, 7]          36,928\n",
            "              ReLU-6             [32, 64, 7, 7]               0\n",
            "           Flatten-7                 [32, 3136]               0\n",
            "            Linear-8                  [32, 512]       1,606,144\n",
            "              ReLU-9                  [32, 512]               0\n",
            "           Linear-10                    [32, 6]           3,078\n",
            "================================================================\n",
            "Total params: 1,687,206\n",
            "Trainable params: 1,687,206\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.45\n",
            "Forward/backward pass size (MB): 11.33\n",
            "Params size (MB): 6.44\n",
            "Estimated Total Size (MB): 21.21\n",
            "----------------------------------------------------------------\n",
            "Episode 0 completed: global_step=597,\tepisodic_return=58.9,\tscore=100\n",
            "Episode 1 completed: global_step=1121,\tepisodic_return=-34.4,\tscore=0\n",
            "Episode 2 completed: global_step=1623,\tepisodic_return=-37.3,\tscore=0\n",
            "Episode 3 completed: global_step=2018,\tepisodic_return=-51.9,\tscore=0\n",
            "Episode 4 completed: global_step=2250,\tepisodic_return=-73.9,\tscore=0\n",
            "Episode 5 completed: global_step=2716,\tepisodic_return=-42.2,\tscore=0\n",
            "Episode 6 completed: global_step=3316,\tepisodic_return=61.2,\tscore=100\n",
            "Episode 7 completed: global_step=4050,\tepisodic_return=75.1,\tscore=100\n",
            "Episode 8 completed: global_step=4691,\tepisodic_return=69.9,\tscore=100\n",
            "Episode 9 completed: global_step=5217,\tepisodic_return=53.9,\tscore=100\n",
            "Episode 10 completed: global_step=5651,\tepisodic_return=-46.3,\tscore=0\n",
            "Episode 11 completed: global_step=6121,\tepisodic_return=-41.7,\tscore=0\n",
            "Episode 12 completed: global_step=6494,\tepisodic_return=-54.8,\tscore=0\n",
            "Episode 13 completed: global_step=6846,\tepisodic_return=-57.4,\tscore=0\n",
            "Episode 14 completed: global_step=7326,\tepisodic_return=-40.3,\tscore=0\n",
            "Episode 15 completed: global_step=7632,\tepisodic_return=-63.8,\tscore=0\n",
            "Episode 16 completed: global_step=8277,\tepisodic_return=160.5,\tscore=200\n",
            "Episode 17 completed: global_step=8697,\tepisodic_return=-48.4,\tscore=0\n",
            "Episode 18 completed: global_step=9176,\tepisodic_return=-40.5,\tscore=0\n",
            "Episode 19 completed: global_step=9592,\tepisodic_return=-48.9,\tscore=0\n",
            "Episode 20 completed: global_step=10327,\tepisodic_return=164.6,\tscore=200\n",
            "Episode 21 completed: global_step=10754,\tepisodic_return=-47.5,\tscore=0\n",
            "Episode 22 completed: global_step=11485,\tepisodic_return=157.3,\tscore=200\n",
            "Episode 23 completed: global_step=12104,\tepisodic_return=58.9,\tscore=100\n",
            "Episode 24 completed: global_step=12684,\tepisodic_return=56.2,\tscore=100\n",
            "Episode 25 completed: global_step=13047,\tepisodic_return=-56.0,\tscore=0\n",
            "Episode 26 completed: global_step=13745,\tepisodic_return=152.4,\tscore=200\n",
            "Episode 27 completed: global_step=14211,\tepisodic_return=-42.1,\tscore=0\n",
            "Episode 28 completed: global_step=14732,\tepisodic_return=-34.6,\tscore=0\n",
            "Episode 29 completed: global_step=15171,\tepisodic_return=-45.9,\tscore=0\n",
            "Episode 30 completed: global_step=16201,\tepisodic_return=566.5,\tscore=600\n",
            "Episode 31 completed: global_step=16807,\tepisodic_return=58.0,\tscore=100\n",
            "Episode 32 completed: global_step=17529,\tepisodic_return=157.1,\tscore=200\n",
            "Episode 33 completed: global_step=18084,\tepisodic_return=-30.0,\tscore=0\n",
            "Episode 34 completed: global_step=18397,\tepisodic_return=-62.8,\tscore=0\n",
            "Episode 35 completed: global_step=19027,\tepisodic_return=68.2,\tscore=100\n",
            "Episode 36 completed: global_step=19426,\tepisodic_return=-51.4,\tscore=0\n",
            "Episode 37 completed: global_step=19838,\tepisodic_return=-49.6,\tscore=0\n",
            "Episode 38 completed: global_step=20303,\tepisodic_return=-42.2,\tscore=0\n",
            "Episode 39 completed: global_step=21020,\tepisodic_return=167.5,\tscore=200\n",
            "Episode 40 completed: global_step=21491,\tepisodic_return=-41.6,\tscore=0\n",
            "Episode 41 completed: global_step=21962,\tepisodic_return=-41.6,\tscore=0\n",
            "Episode 42 completed: global_step=22595,\tepisodic_return=76.6,\tscore=100\n",
            "Episode 43 completed: global_step=22992,\tepisodic_return=-51.3,\tscore=0\n",
            "Episode 44 completed: global_step=23467,\tepisodic_return=-40.8,\tscore=0\n",
            "Episode 45 completed: global_step=24103,\tepisodic_return=69.3,\tscore=100\n",
            "Episode 46 completed: global_step=24517,\tepisodic_return=-49.3,\tscore=0\n",
            "Episode 47 completed: global_step=25036,\tepisodic_return=-35.0,\tscore=0\n",
            "Episode 48 completed: global_step=25679,\tepisodic_return=64.2,\tscore=100\n",
            "Episode 49 completed: global_step=26107,\tepisodic_return=-47.3,\tscore=0\n",
            "Episode 50 completed: global_step=26399,\tepisodic_return=-65.8,\tscore=0\n",
            "Episode 51 completed: global_step=26965,\tepisodic_return=61.6,\tscore=100\n",
            "Episode 52 completed: global_step=27428,\tepisodic_return=-42.7,\tscore=0\n",
            "Episode 53 completed: global_step=27914,\tepisodic_return=49.3,\tscore=100\n",
            "Episode 54 completed: global_step=28689,\tepisodic_return=261.9,\tscore=300\n",
            "Episode 55 completed: global_step=29236,\tepisodic_return=-31.0,\tscore=0\n",
            "Episode 56 completed: global_step=29597,\tepisodic_return=-56.4,\tscore=0\n",
            "Episode 57 completed: global_step=30121,\tepisodic_return=-34.4,\tscore=0\n",
            "Episode 58 completed: global_step=30597,\tepisodic_return=46.2,\tscore=100\n",
            "Episode 59 completed: global_step=31002,\tepisodic_return=-50.3,\tscore=0\n",
            "Episode 60 completed: global_step=31420,\tepisodic_return=-48.5,\tscore=0\n",
            "Episode 61 completed: global_step=31859,\tepisodic_return=-45.8,\tscore=0\n",
            "Episode 62 completed: global_step=32219,\tepisodic_return=-56.4,\tscore=0\n",
            "Episode 63 completed: global_step=32674,\tepisodic_return=-43.5,\tscore=0\n",
            "Episode 64 completed: global_step=33208,\tepisodic_return=-33.0,\tscore=0\n",
            "Episode 65 completed: global_step=33917,\tepisodic_return=157.5,\tscore=200\n",
            "Episode 66 completed: global_step=34404,\tepisodic_return=-39.4,\tscore=0\n",
            "Episode 67 completed: global_step=35046,\tepisodic_return=65.7,\tscore=100\n",
            "Episode 68 completed: global_step=35470,\tepisodic_return=-47.9,\tscore=0\n",
            "Episode 69 completed: global_step=36074,\tepisodic_return=141.6,\tscore=200\n",
            "Episode 70 completed: global_step=36596,\tepisodic_return=-34.6,\tscore=0\n",
            "Episode 71 completed: global_step=36963,\tepisodic_return=-55.5,\tscore=0\n",
            "Episode 72 completed: global_step=37581,\tepisodic_return=66.4,\tscore=100\n",
            "Episode 73 completed: global_step=38410,\tepisodic_return=271.9,\tscore=300\n",
            "Episode 74 completed: global_step=38917,\tepisodic_return=-36.7,\tscore=0\n",
            "Episode 75 completed: global_step=39385,\tepisodic_return=-42.0,\tscore=0\n",
            "Episode 76 completed: global_step=39983,\tepisodic_return=150.5,\tscore=200\n",
            "Episode 77 completed: global_step=40423,\tepisodic_return=-45.7,\tscore=0\n",
            "Episode 78 completed: global_step=40866,\tepisodic_return=-45.3,\tscore=0\n",
            "Episode 79 completed: global_step=41534,\tepisodic_return=242.0,\tscore=300\n",
            "Episode 80 completed: global_step=42092,\tepisodic_return=-29.6,\tscore=0\n",
            "Episode 81 completed: global_step=42622,\tepisodic_return=-33.6,\tscore=0\n",
            "Episode 82 completed: global_step=43210,\tepisodic_return=59.5,\tscore=100\n",
            "Episode 83 completed: global_step=43808,\tepisodic_return=59.9,\tscore=100\n",
            "Episode 84 completed: global_step=44373,\tepisodic_return=52.0,\tscore=100\n",
            "Episode 85 completed: global_step=44695,\tepisodic_return=-61.5,\tscore=0\n",
            "Episode 86 completed: global_step=45282,\tepisodic_return=55.9,\tscore=100\n",
            "Episode 87 completed: global_step=45834,\tepisodic_return=58.5,\tscore=100\n",
            "Episode 88 completed: global_step=46318,\tepisodic_return=-39.8,\tscore=0\n",
            "Episode 89 completed: global_step=47115,\tepisodic_return=272.8,\tscore=300\n",
            "Episode 90 completed: global_step=47784,\tepisodic_return=71.7,\tscore=100\n",
            "Episode 91 completed: global_step=48421,\tepisodic_return=151.5,\tscore=200\n",
            "Episode 92 completed: global_step=48877,\tepisodic_return=-43.6,\tscore=0\n",
            "Episode 93 completed: global_step=49426,\tepisodic_return=-30.9,\tscore=0\n",
            "Episode 94 completed: global_step=50179,\tepisodic_return=166.3,\tscore=200\n",
            "Episode 95 completed: global_step=50963,\tepisodic_return=163.5,\tscore=200\n",
            "Episode 96 completed: global_step=51421,\tepisodic_return=-43.1,\tscore=0\n",
            "Episode 97 completed: global_step=52214,\tepisodic_return=342.0,\tscore=400\n",
            "Episode 98 completed: global_step=53012,\tepisodic_return=263.0,\tscore=300\n",
            "Episode 99 completed: global_step=53631,\tepisodic_return=61.1,\tscore=100\n",
            "Episode 100 completed: global_step=54102,\tepisodic_return=-41.5,\tscore=0\n",
            "Episode 101 completed: global_step=54634,\tepisodic_return=-33.2,\tscore=0\n",
            "Episode 102 completed: global_step=55180,\tepisodic_return=-31.4,\tscore=0\n",
            "Episode 103 completed: global_step=55697,\tepisodic_return=-35.3,\tscore=0\n",
            "Episode 104 completed: global_step=56193,\tepisodic_return=-38.1,\tscore=0\n",
            "Episode 105 completed: global_step=56682,\tepisodic_return=44.1,\tscore=100\n",
            "Episode 106 completed: global_step=57311,\tepisodic_return=151.4,\tscore=200\n",
            "Episode 107 completed: global_step=58044,\tepisodic_return=163.3,\tscore=200\n",
            "Episode 108 completed: global_step=58496,\tepisodic_return=-43.9,\tscore=0\n",
            "Episode 109 completed: global_step=59433,\tepisodic_return=269.1,\tscore=300\n",
            "Episode 110 completed: global_step=59983,\tepisodic_return=-30.5,\tscore=0\n",
            "Episode 111 completed: global_step=60457,\tepisodic_return=44.1,\tscore=100\n",
            "Episode 112 completed: global_step=60973,\tepisodic_return=-35.3,\tscore=0\n",
            "Episode 113 completed: global_step=61473,\tepisodic_return=-37.6,\tscore=0\n",
            "Episode 114 completed: global_step=62193,\tepisodic_return=73.3,\tscore=100\n",
            "Episode 115 completed: global_step=62654,\tepisodic_return=-42.7,\tscore=0\n",
            "Episode 116 completed: global_step=63621,\tepisodic_return=366.1,\tscore=400\n",
            "Episode 117 completed: global_step=64128,\tepisodic_return=-36.7,\tscore=0\n",
            "Episode 118 completed: global_step=64821,\tepisodic_return=68.9,\tscore=100\n",
            "Episode 119 completed: global_step=65383,\tepisodic_return=54.0,\tscore=100\n",
            "Episode 120 completed: global_step=66212,\tepisodic_return=170.3,\tscore=200\n",
            "Episode 121 completed: global_step=66733,\tepisodic_return=52.1,\tscore=100\n",
            "Episode 122 completed: global_step=67200,\tepisodic_return=-41.9,\tscore=0\n",
            "Episode 123 completed: global_step=68238,\tepisodic_return=366.9,\tscore=400\n",
            "Episode 124 completed: global_step=68769,\tepisodic_return=-33.4,\tscore=0\n",
            "Episode 125 completed: global_step=69491,\tepisodic_return=154.6,\tscore=200\n",
            "Episode 126 completed: global_step=70236,\tepisodic_return=160.4,\tscore=200\n",
            "Episode 127 completed: global_step=70895,\tepisodic_return=68.6,\tscore=100\n",
            "Episode 128 completed: global_step=71800,\tepisodic_return=361.2,\tscore=400\n",
            "Episode 129 completed: global_step=72130,\tepisodic_return=-60.7,\tscore=0\n",
            "Episode 130 completed: global_step=72503,\tepisodic_return=-54.9,\tscore=0\n",
            "Episode 131 completed: global_step=73050,\tepisodic_return=49.1,\tscore=100\n",
            "Episode 132 completed: global_step=73668,\tepisodic_return=65.9,\tscore=100\n",
            "Episode 133 completed: global_step=74067,\tepisodic_return=-51.3,\tscore=0\n",
            "Episode 134 completed: global_step=74794,\tepisodic_return=163.1,\tscore=200\n",
            "Episode 135 completed: global_step=75391,\tepisodic_return=150.1,\tscore=200\n",
            "Episode 136 completed: global_step=76058,\tepisodic_return=151.8,\tscore=200\n",
            "Episode 137 completed: global_step=76803,\tepisodic_return=265.3,\tscore=300\n",
            "Episode 138 completed: global_step=77396,\tepisodic_return=67.7,\tscore=100\n",
            "Episode 139 completed: global_step=78158,\tepisodic_return=170.0,\tscore=200\n",
            "Episode 140 completed: global_step=78580,\tepisodic_return=-48.2,\tscore=0\n",
            "Episode 141 completed: global_step=79194,\tepisodic_return=58.6,\tscore=100\n",
            "Episode 142 completed: global_step=79961,\tepisodic_return=259.2,\tscore=300\n",
            "Episode 143 completed: global_step=80694,\tepisodic_return=167.6,\tscore=200\n",
            "Episode 144 completed: global_step=81129,\tepisodic_return=-46.4,\tscore=0\n",
            "Episode 145 completed: global_step=81666,\tepisodic_return=-32.6,\tscore=0\n",
            "Episode 146 completed: global_step=82112,\tepisodic_return=-44.9,\tscore=0\n",
            "Episode 147 completed: global_step=82567,\tepisodic_return=-43.7,\tscore=0\n",
            "Episode 148 completed: global_step=83110,\tepisodic_return=-31.6,\tscore=0\n",
            "Episode 149 completed: global_step=83594,\tepisodic_return=-39.8,\tscore=0\n",
            "Episode 150 completed: global_step=84018,\tepisodic_return=-48.0,\tscore=0\n",
            "Episode 151 completed: global_step=84841,\tepisodic_return=263.4,\tscore=300\n",
            "Episode 152 completed: global_step=85193,\tepisodic_return=-57.6,\tscore=0\n",
            "Episode 153 completed: global_step=85801,\tepisodic_return=139.0,\tscore=200\n",
            "Episode 154 completed: global_step=86297,\tepisodic_return=50.4,\tscore=100\n",
            "Episode 155 completed: global_step=86791,\tepisodic_return=-38.4,\tscore=0\n",
            "Episode 156 completed: global_step=87688,\tepisodic_return=361.9,\tscore=400\n",
            "Episode 157 completed: global_step=88573,\tepisodic_return=346.7,\tscore=400\n",
            "Episode 158 completed: global_step=89124,\tepisodic_return=54.0,\tscore=100\n",
            "Episode 159 completed: global_step=89754,\tepisodic_return=61.4,\tscore=100\n",
            "Episode 160 completed: global_step=90741,\tepisodic_return=364.4,\tscore=400\n",
            "Episode 161 completed: global_step=91250,\tepisodic_return=46.4,\tscore=100\n",
            "Episode 162 completed: global_step=91753,\tepisodic_return=-36.9,\tscore=0\n",
            "Episode 163 completed: global_step=92418,\tepisodic_return=66.5,\tscore=100\n",
            "Episode 164 completed: global_step=92909,\tepisodic_return=-38.6,\tscore=0\n",
            "Episode 165 completed: global_step=93470,\tepisodic_return=-29.3,\tscore=0\n",
            "Episode 166 completed: global_step=94188,\tepisodic_return=78.4,\tscore=100\n",
            "Episode 167 completed: global_step=94699,\tepisodic_return=-35.9,\tscore=0\n",
            "Episode 168 completed: global_step=95505,\tepisodic_return=174.5,\tscore=200\n",
            "Episode 169 completed: global_step=96156,\tepisodic_return=144.4,\tscore=200\n",
            "Episode 170 completed: global_step=96958,\tepisodic_return=265.4,\tscore=300\n",
            "Episode 171 completed: global_step=97325,\tepisodic_return=-55.5,\tscore=0\n",
            "Episode 172 completed: global_step=97956,\tepisodic_return=60.7,\tscore=100\n",
            "Episode 173 completed: global_step=98434,\tepisodic_return=-40.6,\tscore=0\n",
            "Episode 174 completed: global_step=98960,\tepisodic_return=-33.9,\tscore=0\n",
            "Episode 175 completed: global_step=99402,\tepisodic_return=-45.5,\tscore=0\n",
            "Episode 176 completed: global_step=100526,\tepisodic_return=557.9,\tscore=600\n",
            "Episode 177 completed: global_step=101348,\tepisodic_return=170.6,\tscore=200\n",
            "Episode 178 completed: global_step=101800,\tepisodic_return=-44.2,\tscore=0\n",
            "Episode 179 completed: global_step=102280,\tepisodic_return=-40.3,\tscore=0\n",
            "Episode 180 completed: global_step=103290,\tepisodic_return=367.8,\tscore=400\n",
            "Episode 181 completed: global_step=103921,\tepisodic_return=67.9,\tscore=100\n",
            "Episode 182 completed: global_step=105139,\tepisodic_return=569.9,\tscore=600\n",
            "Episode 183 completed: global_step=106233,\tepisodic_return=551.8,\tscore=600\n",
            "Episode 184 completed: global_step=107304,\tepisodic_return=567.4,\tscore=600\n",
            "Episode 185 completed: global_step=108382,\tepisodic_return=364.4,\tscore=400\n",
            "Episode 186 completed: global_step=109242,\tepisodic_return=254.9,\tscore=300\n",
            "Episode 187 completed: global_step=109890,\tepisodic_return=66.5,\tscore=100\n",
            "Episode 188 completed: global_step=110673,\tepisodic_return=262.4,\tscore=300\n",
            "Episode 189 completed: global_step=111405,\tepisodic_return=154.8,\tscore=200\n",
            "Episode 190 completed: global_step=112289,\tepisodic_return=269.3,\tscore=300\n",
            "Episode 191 completed: global_step=112801,\tepisodic_return=-36.0,\tscore=0\n",
            "Episode 192 completed: global_step=113394,\tepisodic_return=56.2,\tscore=100\n",
            "Episode 193 completed: global_step=113998,\tepisodic_return=57.1,\tscore=100\n",
            "Episode 194 completed: global_step=114718,\tepisodic_return=170.7,\tscore=200\n",
            "Episode 195 completed: global_step=115341,\tepisodic_return=147.0,\tscore=200\n",
            "Episode 196 completed: global_step=115899,\tepisodic_return=57.4,\tscore=100\n",
            "Episode 197 completed: global_step=116401,\tepisodic_return=-37.4,\tscore=0\n",
            "Episode 198 completed: global_step=117187,\tepisodic_return=162.2,\tscore=200\n",
            "Episode 199 completed: global_step=118467,\tepisodic_return=777.0,\tscore=800\n",
            "Episode 200 completed: global_step=119455,\tepisodic_return=355.9,\tscore=400\n",
            "Episode 201 completed: global_step=120083,\tepisodic_return=60.2,\tscore=100\n",
            "Episode 202 completed: global_step=121045,\tepisodic_return=269.8,\tscore=300\n",
            "Episode 203 completed: global_step=121735,\tepisodic_return=149.4,\tscore=200\n",
            "Episode 204 completed: global_step=122618,\tepisodic_return=258.6,\tscore=300\n",
            "Episode 205 completed: global_step=123565,\tepisodic_return=265.9,\tscore=300\n",
            "Episode 206 completed: global_step=124122,\tepisodic_return=50.9,\tscore=100\n",
            "Episode 207 completed: global_step=124879,\tepisodic_return=159.0,\tscore=200\n",
            "Episode 208 completed: global_step=126353,\tepisodic_return=1663.0,\tscore=1700\n",
            "Episode 209 completed: global_step=126846,\tepisodic_return=-38.6,\tscore=0\n",
            "Episode 210 completed: global_step=127722,\tepisodic_return=340.1,\tscore=400\n",
            "Episode 211 completed: global_step=128265,\tepisodic_return=49.3,\tscore=100\n",
            "Episode 212 completed: global_step=128785,\tepisodic_return=-34.8,\tscore=0\n",
            "Episode 213 completed: global_step=129355,\tepisodic_return=133.8,\tscore=200\n",
            "Episode 214 completed: global_step=130146,\tepisodic_return=167.4,\tscore=200\n",
            "Episode 215 completed: global_step=131722,\tepisodic_return=1662.4,\tscore=1700\n",
            "Episode 216 completed: global_step=132474,\tepisodic_return=157.7,\tscore=200\n",
            "Episode 217 completed: global_step=133974,\tepisodic_return=1156.8,\tscore=1200\n",
            "Episode 218 completed: global_step=134683,\tepisodic_return=168.2,\tscore=200\n",
            "Episode 219 completed: global_step=135403,\tepisodic_return=153.8,\tscore=200\n",
            "Episode 220 completed: global_step=136083,\tepisodic_return=162.4,\tscore=200\n",
            "Episode 221 completed: global_step=137324,\tepisodic_return=766.5,\tscore=800\n",
            "Episode 222 completed: global_step=138053,\tepisodic_return=160.6,\tscore=200\n",
            "Episode 223 completed: global_step=139162,\tepisodic_return=369.1,\tscore=400\n",
            "Episode 224 completed: global_step=139512,\tepisodic_return=-58.0,\tscore=0\n",
            "Episode 225 completed: global_step=140800,\tepisodic_return=767.5,\tscore=800\n",
            "Episode 226 completed: global_step=141753,\tepisodic_return=364.6,\tscore=400\n",
            "Episode 227 completed: global_step=142629,\tepisodic_return=259.0,\tscore=300\n",
            "Episode 228 completed: global_step=143733,\tepisodic_return=555.2,\tscore=600\n",
            "Episode 229 completed: global_step=144265,\tepisodic_return=-33.3,\tscore=0\n",
            "Episode 230 completed: global_step=145185,\tepisodic_return=262.5,\tscore=300\n",
            "Episode 231 completed: global_step=145709,\tepisodic_return=-34.3,\tscore=0\n",
            "Episode 232 completed: global_step=146282,\tepisodic_return=-27.5,\tscore=0\n",
            "Episode 233 completed: global_step=146927,\tepisodic_return=62.4,\tscore=100\n",
            "Episode 234 completed: global_step=147939,\tepisodic_return=357.5,\tscore=400\n",
            "Episode 235 completed: global_step=148510,\tepisodic_return=59.2,\tscore=100\n",
            "Episode 236 completed: global_step=149598,\tepisodic_return=364.1,\tscore=400\n",
            "Episode 237 completed: global_step=150331,\tepisodic_return=161.2,\tscore=200\n",
            "Episode 238 completed: global_step=151016,\tepisodic_return=67.8,\tscore=100\n",
            "Episode 239 completed: global_step=151760,\tepisodic_return=157.8,\tscore=200\n",
            "Episode 240 completed: global_step=153014,\tepisodic_return=757.3,\tscore=800\n",
            "Episode 241 completed: global_step=154027,\tepisodic_return=364.9,\tscore=400\n",
            "Episode 242 completed: global_step=154539,\tepisodic_return=52.8,\tscore=100\n",
            "Episode 243 completed: global_step=155784,\tepisodic_return=942.8,\tscore=1000\n",
            "Episode 244 completed: global_step=156380,\tepisodic_return=56.2,\tscore=100\n",
            "Episode 245 completed: global_step=157267,\tepisodic_return=262.9,\tscore=300\n",
            "Episode 246 completed: global_step=157952,\tepisodic_return=67.9,\tscore=100\n",
            "Episode 247 completed: global_step=158682,\tepisodic_return=158.0,\tscore=200\n",
            "Episode 248 completed: global_step=159372,\tepisodic_return=149.3,\tscore=200\n",
            "Episode 249 completed: global_step=161272,\tepisodic_return=2571.4,\tscore=2600\n",
            "Episode 250 completed: global_step=161747,\tepisodic_return=-41.0,\tscore=0\n",
            "Episode 251 completed: global_step=162251,\tepisodic_return=-37.0,\tscore=0\n",
            "Episode 252 completed: global_step=163617,\tepisodic_return=773.2,\tscore=800\n",
            "Episode 253 completed: global_step=164311,\tepisodic_return=172.0,\tscore=200\n",
            "Episode 254 completed: global_step=165556,\tepisodic_return=757.5,\tscore=800\n",
            "Episode 255 completed: global_step=166806,\tepisodic_return=774.6,\tscore=800\n",
            "Episode 256 completed: global_step=168105,\tepisodic_return=771.4,\tscore=800\n",
            "Episode 257 completed: global_step=168735,\tepisodic_return=60.8,\tscore=100\n",
            "Episode 258 completed: global_step=169498,\tepisodic_return=170.8,\tscore=200\n",
            "Episode 259 completed: global_step=170231,\tepisodic_return=156.2,\tscore=200\n",
            "Episode 260 completed: global_step=171271,\tepisodic_return=554.4,\tscore=600\n",
            "Episode 261 completed: global_step=172024,\tepisodic_return=158.9,\tscore=200\n",
            "Episode 262 completed: global_step=173143,\tepisodic_return=767.0,\tscore=800\n",
            "Episode 263 completed: global_step=173755,\tepisodic_return=65.0,\tscore=100\n",
            "Episode 264 completed: global_step=175614,\tepisodic_return=2548.6,\tscore=2600\n",
            "Episode 265 completed: global_step=176168,\tepisodic_return=131.9,\tscore=200\n",
            "Episode 266 completed: global_step=176978,\tepisodic_return=266.9,\tscore=300\n",
            "Episode 267 completed: global_step=177599,\tepisodic_return=61.4,\tscore=100\n",
            "Episode 268 completed: global_step=178610,\tepisodic_return=557.8,\tscore=600\n",
            "Episode 269 completed: global_step=179082,\tepisodic_return=-41.4,\tscore=0\n",
            "Episode 270 completed: global_step=180384,\tepisodic_return=970.9,\tscore=1000\n",
            "Episode 271 completed: global_step=181230,\tepisodic_return=264.9,\tscore=300\n",
            "Episode 272 completed: global_step=181655,\tepisodic_return=-47.8,\tscore=0\n",
            "Episode 273 completed: global_step=183086,\tepisodic_return=976.1,\tscore=1000\n",
            "Episode 274 completed: global_step=184130,\tepisodic_return=363.6,\tscore=400\n",
            "Episode 275 completed: global_step=185511,\tepisodic_return=969.2,\tscore=1000\n",
            "Episode 276 completed: global_step=186482,\tepisodic_return=270.1,\tscore=300\n",
            "Episode 277 completed: global_step=187118,\tepisodic_return=63.6,\tscore=100\n",
            "Episode 278 completed: global_step=187897,\tepisodic_return=249.0,\tscore=300\n",
            "Episode 279 completed: global_step=188711,\tepisodic_return=262.1,\tscore=300\n",
            "Episode 280 completed: global_step=190246,\tepisodic_return=1165.9,\tscore=1200\n",
            "Episode 281 completed: global_step=191849,\tepisodic_return=1365.9,\tscore=1400\n",
            "Episode 282 completed: global_step=194120,\tepisodic_return=3675.1,\tscore=3700\n",
            "Episode 283 completed: global_step=195672,\tepisodic_return=1361.6,\tscore=1400\n",
            "Episode 284 completed: global_step=197459,\tepisodic_return=2266.2,\tscore=2300\n",
            "Episode 285 completed: global_step=199633,\tepisodic_return=3651.7,\tscore=3700\n",
            "Episode 286 completed: global_step=202896,\tepisodic_return=12449.4,\tscore=12500\n",
            "Episode 287 completed: global_step=205040,\tepisodic_return=3255.6,\tscore=3300\n",
            "Episode 288 completed: global_step=206395,\tepisodic_return=974.1,\tscore=1000\n",
            "Episode 289 completed: global_step=207220,\tepisodic_return=168.3,\tscore=200\n",
            "Episode 290 completed: global_step=208305,\tepisodic_return=567.9,\tscore=600\n",
            "Episode 291 completed: global_step=209821,\tepisodic_return=1165.2,\tscore=1200\n",
            "Episode 292 completed: global_step=210609,\tepisodic_return=168.9,\tscore=200\n",
            "Episode 293 completed: global_step=213840,\tepisodic_return=10367.5,\tscore=10400\n",
            "Episode 294 completed: global_step=215325,\tepisodic_return=1660.0,\tscore=1700\n",
            "Episode 295 completed: global_step=216344,\tepisodic_return=760.7,\tscore=800\n",
            "Episode 296 completed: global_step=217468,\tepisodic_return=767.8,\tscore=800\n",
            "Episode 297 completed: global_step=219180,\tepisodic_return=1664.9,\tscore=1700\n",
            "Episode 298 completed: global_step=221375,\tepisodic_return=2868.0,\tscore=2900\n",
            "Episode 299 completed: global_step=222822,\tepisodic_return=967.8,\tscore=1000\n",
            "Episode 300 completed: global_step=225049,\tepisodic_return=2864.3,\tscore=2900\n",
            "Episode 301 completed: global_step=226126,\tepisodic_return=362.1,\tscore=400\n",
            "Episode 302 completed: global_step=227141,\tepisodic_return=760.7,\tscore=800\n",
            "Episode 303 completed: global_step=228953,\tepisodic_return=2551.3,\tscore=2600\n",
            "Episode 304 completed: global_step=230849,\tepisodic_return=1966.6,\tscore=2000\n",
            "Episode 305 completed: global_step=232380,\tepisodic_return=1167.9,\tscore=1200\n",
            "Episode 306 completed: global_step=233422,\tepisodic_return=568.1,\tscore=600\n",
            "Episode 307 completed: global_step=234276,\tepisodic_return=353.2,\tscore=400\n",
            "Episode 308 completed: global_step=234907,\tepisodic_return=71.4,\tscore=100\n",
            "Episode 309 completed: global_step=237019,\tepisodic_return=2566.3,\tscore=2600\n",
            "Episode 310 completed: global_step=237652,\tepisodic_return=60.9,\tscore=100\n",
            "Episode 311 completed: global_step=241028,\tepisodic_return=11767.7,\tscore=11800\n",
            "Episode 312 completed: global_step=242138,\tepisodic_return=563.2,\tscore=600\n",
            "Episode 313 completed: global_step=243260,\tepisodic_return=560.2,\tscore=600\n",
            "Episode 314 completed: global_step=244885,\tepisodic_return=1962.5,\tscore=2000\n",
            "Episode 315 completed: global_step=246863,\tepisodic_return=2548.6,\tscore=2600\n",
            "Episode 316 completed: global_step=247821,\tepisodic_return=366.0,\tscore=400\n",
            "Episode 317 completed: global_step=249767,\tepisodic_return=2857.8,\tscore=2900\n",
            "Episode 318 completed: global_step=250976,\tepisodic_return=570.8,\tscore=600\n"
          ]
        }
      ],
      "source": [
        "args = Args()\n",
        "train(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q-ZggO-qtbL"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# device = 'cuda'\n",
        "# state_dict = torch.load('SavedModels/score_1k_incosistent.backup', device)\n",
        "# q_network = QNetwork(6,4).to(device)\n",
        "# q_network.load_state_dict(state_dict)\n",
        "\n",
        "# scores = evaluate(\n",
        "#     q_network,\n",
        "#     args.env_id,\n",
        "#     args.eval_episodes,\n",
        "#     run_name=f\"temp-eval\",\n",
        "#     seed=args.seed,\n",
        "#     device=device,\n",
        "#     capture_video=args.capture_video,\n",
        "#     frame_stack=4\n",
        "# )\n",
        "\n",
        "# print(\"Eval Scores:\", scores)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "W1KbrN9Li5i8",
        "ORRWWz8dIqaH"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tetrisenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "4a7f40d72114c62e91de8d79ab05a4f10d2c48422b550572d6072f074507511d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
