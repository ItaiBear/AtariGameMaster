{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "74u8GL2dfD2F"
      },
      "outputs": [],
      "source": [
        "!rm -rf runs videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1KbrN9Li5i8"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSm_UBPsLzq_",
        "outputId": "39d8ba22-4808-4519-d1ce-388cb794e306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym-tetris\n",
            "  Downloading gym_tetris-3.0.4-py3-none-any.whl (34 kB)\n",
            "Collecting nes-py>=8.1.4\n",
            "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.9/dist-packages (from nes-py>=8.1.4->gym-tetris) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from nes-py>=8.1.4->gym-tetris) (1.22.4)\n",
            "Collecting pyglet<=1.5.21,>=1.4.0\n",
            "  Downloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.9/dist-packages (from nes-py>=8.1.4->gym-tetris) (4.65.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-tetris) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-tetris) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-tetris) (6.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes-py>=8.1.4->gym-tetris) (3.15.0)\n",
            "Building wheels for collected packages: nes-py\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.2.1-cp39-cp39-linux_x86_64.whl size=494880 sha256=43c45a527244fe87c2c1d6755a3e067f8434f9390462d12c08057f829bcd0bbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/e1/4b/dbbd5d4a46ad80c0149d5671edb272c728c130e4d5750ca1d2\n",
            "Successfully built nes-py\n",
            "Installing collected packages: pyglet, nes-py, gym-tetris\n",
            "Successfully installed gym-tetris-3.0.4 nes-py-8.2.1 pyglet-1.5.21\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (23.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyglet==1.5.1\n",
            "  Downloading pyglet-1.5.1-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.5.21\n",
            "    Uninstalling pyglet-1.5.21:\n",
            "      Successfully uninstalled pyglet-1.5.21\n",
            "Successfully installed pyglet-1.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.9/dist-packages (1.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.47)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.2 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna-dashboard\n",
            "  Downloading optuna_dashboard-0.9.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from optuna-dashboard) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from optuna-dashboard) (23.0)\n",
            "Collecting bottle\n",
            "  Downloading bottle-0.12.25-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.2/90.2 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: optuna>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from optuna-dashboard) (3.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna>=2.4.0->optuna-dashboard) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna>=2.4.0->optuna-dashboard) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna>=2.4.0->optuna-dashboard) (1.22.4)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from optuna>=2.4.0->optuna-dashboard) (0.9.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from optuna>=2.4.0->optuna-dashboard) (1.10.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/dist-packages (from optuna>=2.4.0->optuna-dashboard) (6.7.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna>=2.4.0->optuna-dashboard) (1.4.47)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->optuna-dashboard) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->optuna-dashboard) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->optuna-dashboard) (1.10.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna>=2.4.0->optuna-dashboard) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (2.1.2)\n",
            "Installing collected packages: bottle, optuna-dashboard\n",
            "Successfully installed bottle-0.12.25 optuna-dashboard-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gym-tetris\n",
        "!pip install tensorboardX\n",
        "!pip install pyglet==1.5.1\n",
        "!pip install torchsummary\n",
        "!pip install optuna\n",
        "!pip install optuna-dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbigCoubxceQ",
        "outputId": "da980382-8858-44f8-e876-39872e99ac1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting setuptools==65.5.1\n",
            "  Downloading setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.6.1\n",
            "    Uninstalling setuptools-67.6.1:\n",
            "      Successfully uninstalled setuptools-67.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cvxpy 1.3.1 requires setuptools>65.5.1, but you have setuptools 65.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-65.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym==0.21.0\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.21.0) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.21.0) (2.2.1)\n",
            "Building wheels for collected packages: gym\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gym\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gym\n",
            "Failed to build gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Running setup.py install for gym ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: gym was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed gym-0.21.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/171.8 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Collecting importlib-metadata~=4.13\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (0.21.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (1.4.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (2.0.0+cu118)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting ale-py==0.7.4\n",
            "  Downloading ale_py-0.7.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (4.7.0.72)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (5.9.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (8.4.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (2.12.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (13.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from stable-baselines3[extra]) (4.65.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.9/dist-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.27.1)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.6.0.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 KB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.40.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (65.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.17.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.3)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.53.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3[extra]) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3[extra]) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3[extra]) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3[extra]) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3[extra]) (3.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3[extra]) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3[extra]) (3.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3[extra]) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3[extra]) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3[extra]) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->stable-baselines3[extra]) (2022.7.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.2)\n",
            "Collecting libtorrent\n",
            "  Downloading libtorrent-2.0.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.11->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.0-py3-none-any.whl size=446686 sha256=ab2373941e567d13a8a0bfa106a2b07bf0eea688694b9d362d1e3f121a032c5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/17/c9/c31922a6aaf4ec7ec90eeee5dbc40ffbaafeda64b30a208b72\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: libtorrent, importlib-metadata, AutoROM.accept-rom-license, autorom, ale-py, stable-baselines3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.1.0\n",
            "    Uninstalling importlib-metadata-6.1.0:\n",
            "      Successfully uninstalled importlib-metadata-6.1.0\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.0 ale-py-0.7.4 autorom-0.4.2 importlib-metadata-4.13.0 libtorrent-2.0.7 stable-baselines3-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install setuptools==65.5.1\n",
        "!pip install gym==0.21.0\n",
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc0SC4CrMXSk",
        "outputId": "72a96155-d3d3-4f64-e143-6913e97a2d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-525\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 780 kB of archives.\n",
            "After this operation, 2,271 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.8 [780 kB]\n",
            "Fetched 780 kB in 1s (1,093 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 128293 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install pyvirtualdisplay\n",
        "!apt-get install -y xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1NHYcVNMQaW",
        "outputId": "48e3c777-fc26-4b63-eba1-6e11e47aa30c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x1080abe50>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1024, 768))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Get the absolute path to the parent directory of gym-tetris\n",
        "gym_tetris_parent_path = os.path.abspath(os.path.join('..', 'gym-tetris'))\n",
        "\n",
        "# Append the path to the sys.path\n",
        "sys.path.append(gym_tetris_parent_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORRWWz8dIqaH"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAZVhbsLMHdd",
        "outputId": "38351819-5de4-4496-c0d9-f9fc27a5ce70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "action space:  ()\n",
            "(240, 256, 3)\n",
            "{'current_piece': 'Jd', 'number_of_lines': 0, 'score': 0, 'next_piece': 'Ih', 'statistics': {'T': 0, 'J': 1, 'Z': 0, 'O': 0, 'S': 0, 'L': 0, 'I': 0}, 'board_height': 0}\n"
          ]
        }
      ],
      "source": [
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_tetris\n",
        "from gym_tetris.actions import MOVEMENT\n",
        "\n",
        "env = gym_tetris.make('TetrisA-v0')\n",
        "env = JoypadSpace(env, MOVEMENT)\n",
        "\n",
        "print(\"action space: \", env.action_space.shape)\n",
        "#print(\"observation space: \", env.observation_shape.shape)\n",
        "\n",
        "done = True\n",
        "for step in range(1):\n",
        "    if done:\n",
        "        state = env.reset()\n",
        "    print(state.shape)\n",
        "    state, reward, done, info = env.step(env.action_space.sample())\n",
        "    print(info)\n",
        "    env.render()\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQI2Rw4wHCP2",
        "outputId": "e46831e0-cca4-47f2-f664-33c902d5b408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "action space:  None\n",
            "(1, 4, 84, 84)\n",
            "[{'lives': 3, 'episode_frame_number': 3, 'frame_number': 3}]\n"
          ]
        }
      ],
      "source": [
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_tetris\n",
        "from gym_tetris.actions import MOVEMENT\n",
        "\n",
        "envs = gym.vector.SyncVectorEnv([make_env(env_id=\"SpaceInvadersNoFrameskip-v4\", seed=1, idx=0, capture_video=0, run_name=\"test\")])\n",
        "\n",
        "print(\"action space: \", envs.action_space.shape)\n",
        "#print(\"observation space: \", env.observation_shape.shape)\n",
        "\n",
        "done = True\n",
        "for step in range(1):\n",
        "    if done:\n",
        "        state = envs.reset()\n",
        "    print(state.shape)\n",
        "    state, reward, done, info = envs.step(envs.action_space.sample())\n",
        "    print(info)\n",
        "    #envs.render()\n",
        "\n",
        "envs.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB-OD5xIv04f"
      },
      "outputs": [],
      "source": [
        "envs = gym.vector.SyncVectorEnv([make_env(env_id=\"TetrisA-v0\", seed=1, idx=0, capture_video=0, run_name=\"test\")])\n",
        "print(\"action space: \", envs.action_space)\n",
        "print(\"observation space: \", envs.observation_space)\n",
        "print(\"single action space: \", envs.single_action_space)\n",
        "print(\"single observation space: \", envs.single_observation_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKXi7x9lw2oW",
        "outputId": "91ff2ee6-6e92-42dc-b7ee-27f90db5d8a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "action space:  Tuple(Discrete(6))\n",
            "observation space:  (1, 4, 84, 84)\n",
            "single action space:  Discrete(6)\n"
          ]
        }
      ],
      "source": [
        "envs = gym.vector.SyncVectorEnv([make_env(env_id=\"SpaceInvadersNoFrameskip-v4\", seed=1, idx=0, capture_video=0, run_name=\"test\")])\n",
        "print(\"action space: \", envs.action_space)\n",
        "print(\"observation space: \", envs.observation_space.shape)\n",
        "print(\"single action space: \", envs.single_action_space)\n",
        "#print(\"single observation space: \", envs.single_observation_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "tEcVDe1dNMp-",
        "outputId": "2f3aabde-2c30-4ba5-ee16-be359cac1ece"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=256x240 at 0x7F4AB7FFFD30>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-842cc5644eca>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2241\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import io\n",
        "import time\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_tetris\n",
        "from gym_tetris.actions import MOVEMENT\n",
        "\n",
        "env = gym_tetris.make('TetrisA-v0')\n",
        "env = JoypadSpace(env, MOVEMENT)\n",
        "\n",
        "done = True\n",
        "for step in range(5000):\n",
        "    if done:\n",
        "        state = env.reset()\n",
        "    state, reward, done, info = env.step(env.action_space.sample())\n",
        "\n",
        "    # Capture the current game frame\n",
        "    buffer = io.BytesIO()\n",
        "    img = env.render(mode='rgb_array')\n",
        "    Image.fromarray(img).save(buffer, 'PNG')\n",
        "    buffer.seek(0)\n",
        "\n",
        "    # Display the frame using IPython.display\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    IPython.display.display(Image.open(buffer))\n",
        "\n",
        "    # Sleep for a short duration (optional, to control the frame rate)\n",
        "    #time.sleep(0.1)\n",
        "\n",
        "IPython.display.clear_output(wait=True)\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kImBr6NFjKIY"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TidRAkGEU0Wl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "from distutils.util import strtobool\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from stable_baselines3.common.atari_wrappers import (\n",
        "    ClipRewardEnv,\n",
        "    EpisodicLifeEnv,\n",
        "    FireResetEnv,\n",
        "    MaxAndSkipEnv,\n",
        "    NoopResetEnv,\n",
        ")\n",
        "from stable_baselines3.common.buffers import ReplayBuffer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_tetris\n",
        "from gym_tetris.actions import MOVEMENT\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'gym_tetris.actions' from '/Users/itaibear/Tetris/AtariGameMaster/gym-tetris/gym_tetris/actions.py'>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "importlib.reload(gym_tetris)\n",
        "importlib.reload(gym_tetris.actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H-rvKojYAuK3"
      },
      "outputs": [],
      "source": [
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, actions_num, arch_fn):\n",
        "        super().__init__()\n",
        "        self.network = arch_fn(actions_num)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x / 255.0)\n",
        "\n",
        "def original(actions_num):\n",
        "    network = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, 8, stride=4),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, 4, stride=2),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 64, 3, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(3136, 512),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, actions_num),\n",
        "    )\n",
        "    return network\n",
        "\n",
        "def tiny(actions_num):\n",
        "    network = nn.Sequential(\n",
        "        nn.Conv2d(1, 8, 3, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(8, 16, 5, stride=3),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 5, stride=3),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(2048, 128),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, actions_num),\n",
        "    )\n",
        "    return network\n",
        "\n",
        "def small(actions_num):\n",
        "    network = nn.Sequential(\n",
        "        # (1, 84, 84)\n",
        "        nn.Conv2d(1, 64, 7, stride=3),\n",
        "        nn.ReLU(),\n",
        "        # (64, 26, 26)\n",
        "        nn.Conv2d(64, 128, 5),\n",
        "        nn.ReLU(),\n",
        "        # (128, 22, 22)\n",
        "        nn.MaxPool2d(2),\n",
        "        # (128, 11, 11)\n",
        "        nn.Conv2d(128, 128, 3),\n",
        "        nn.ReLU(),\n",
        "        # (128, 8, 8)\n",
        "        nn.Conv2d(128, 256, 3),\n",
        "        nn.ReLU(),\n",
        "        # (256, 6, 6)\n",
        "        nn.Conv2d(256, 256, 3),\n",
        "        nn.ReLU(),\n",
        "        # (256, 4, 4)\n",
        "        nn.MaxPool2d(2),\n",
        "        # (256, 2, 2)\n",
        "        nn.Flatten(),\n",
        "        # 1024\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(1024, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(256, actions_num)\n",
        "        # 12 possible actions\n",
        "    )\n",
        "    return network\n",
        "\n",
        "def get_model_class(architecture=\"original\"):\n",
        "    if architecture == \"original\":\n",
        "        class OriginalQNetwork(QNetwork):\n",
        "            def __init__(self, env):\n",
        "                super().__init__(env, original)\n",
        "        return OriginalQNetwork\n",
        "    elif architecture == \"tiny\":\n",
        "        class TinyQNetwork(QNetwork):\n",
        "            def __init__(self, env):\n",
        "                super().__init__(env, tiny)\n",
        "        return TinyQNetwork\n",
        "    elif architecture == \"small\":\n",
        "        class SmallQNetwork(QNetwork):\n",
        "            def __init__(self, env):\n",
        "                super().__init__(env, small)\n",
        "        return SmallQNetwork\n",
        "    else:\n",
        "        print(\"Not a valid architecture\")\n",
        "\n",
        "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
        "    slope = (end_e - start_e) / duration\n",
        "    return max(slope * t + start_e, end_e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esiYvzSJEQrm"
      },
      "outputs": [],
      "source": [
        "Network = get_model_class(\"small\")\n",
        "model = Network(12)\n",
        "summary(model, (1, 84, 84), batch_size=16, device=\"cpu\")\n",
        "x = torch.randn(1, 84, 84)\n",
        "out = model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONY4c-Bo83kG"
      },
      "source": [
        "### Noam Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqtvvItVqugD"
      },
      "outputs": [],
      "source": [
        "# # Network V2 - Noam\n",
        "# class QNetwork(nn.Module):\n",
        "#     def __init__(self, env):\n",
        "#         super().__init__()\n",
        "#         self.network = nn.Sequential(\n",
        "#             # (1, 84, 84)\n",
        "#             nn.Conv2d(1, 32, 8, padding='same'),\n",
        "#             nn.MaxPool2d(3),\n",
        "#             nn.ReLU(),\n",
        "#             # (32, 28, 28)\n",
        "#             nn.Conv2d(32, 64, 4, padding='same'),\n",
        "#             nn.MaxPool2d(2),\n",
        "#             nn.ReLU(),\n",
        "#             # (64, 14, 14)\n",
        "#             nn.Conv2d(64, 64, 3, padding='same'),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2),\n",
        "#             # (64, 7, 7)\n",
        "#             nn.Flatten(),\n",
        "#             # 3136\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(3136, 1024),\n",
        "#             nn.ReLU(),\n",
        "#             # 1024\n",
        "#             nn.Dropout(0.4),\n",
        "#             nn.Linear(1024, 256),\n",
        "#             nn.ReLU(),\n",
        "#             # 256\n",
        "#             nn.Dropout(0.3),\n",
        "#             nn.Linear(256, env.single_action_space.n)\n",
        "#             # 12 possible actions\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.network(x / 255.0)\n",
        "\n",
        "\n",
        "# def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
        "#     slope = (end_e - start_e) / duration\n",
        "#     return max(slope * t + start_e, end_e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhEtC-Myw9uk"
      },
      "outputs": [],
      "source": [
        "# # Network V3 - Noam\n",
        "# class QNetwork(nn.Module):\n",
        "#     def __init__(self, env):\n",
        "#         super().__init__()\n",
        "#         self.network = nn.Sequential(\n",
        "#             # (1, 84, 84)\n",
        "#             nn.Conv2d(1, 64, 4, padding='valid'),\n",
        "#             nn.MaxPool2d(3),\n",
        "#             nn.ReLU(),\n",
        "#             # (64, 27, 27)\n",
        "#             nn.Conv2d(64, 128, 4, padding='valid'),\n",
        "#             # (64, 24, 24)\n",
        "#             nn.MaxPool2d(3),\n",
        "#             nn.ReLU(),\n",
        "#             # (128, 8, 8)\n",
        "#             nn.Conv2d(128, 128, 3, padding='valid'),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2),\n",
        "#             # (128, 3, 3)\n",
        "#             nn.Flatten(),\n",
        "#             # 1152\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(1152, 256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.3),\n",
        "#             nn.Linear(256, env.single_action_space.n)\n",
        "#             # 12 possible actions\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.network(x / 255.0)\n",
        "\n",
        "\n",
        "# def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
        "#     slope = (end_e - start_e) / duration\n",
        "#     return max(slope * t + start_e, end_e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVgtmTDlzWLL"
      },
      "outputs": [],
      "source": [
        "# # Network V4 - Noam\n",
        "# class QNetwork(nn.Module):\n",
        "#     def __init__(self, env):\n",
        "#         super().__init__()\n",
        "#         self.network = nn.Sequential(\n",
        "#             # (1, 84, 84)\n",
        "#             nn.Conv2d(1, 64, 5, padding='valid'),\n",
        "#             # (64, 80, 80)\n",
        "#             nn.MaxPool2d(2),\n",
        "#             nn.ReLU(),\n",
        "#             # (64, 40, 40)\n",
        "#             nn.Conv2d(64, 128, 5, padding='valid'),\n",
        "#             nn.MaxPool2d(2),\n",
        "#             nn.ReLU(),\n",
        "#             # (128, 18, 18)\n",
        "#             nn.Conv2d(128, 128, 3, padding='valid'),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2),\n",
        "#             # (128, 8, 8)\n",
        "#             nn.Conv2d(128, 128, 3, padding='same'),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2),\n",
        "#             # (128, 4, 4)\n",
        "#             nn.Flatten(),\n",
        "#             # 2048\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(2048, 512),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.3),\n",
        "#             nn.Linear(512, env.single_action_space.n)\n",
        "#             # 12 possible actions\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.network(x / 255.0)\n",
        "\n",
        "\n",
        "# def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
        "#     slope = (end_e - start_e) / duration\n",
        "#     return max(slope * t + start_e, end_e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14u8t8bs0aWS"
      },
      "outputs": [],
      "source": [
        "# # Network V5 - Noam\n",
        "# class QNetwork(nn.Module):\n",
        "#     def __init__(self, env):\n",
        "#         super().__init__()\n",
        "#         self.network = nn.Sequential(\n",
        "#             # (1, 84, 84)\n",
        "#             nn.Conv2d(1, 64, 7, stride=3),\n",
        "#             nn.ReLU(),\n",
        "#             # (64, 26, 26)\n",
        "#             nn.Conv2d(64, 128, 5),\n",
        "#             nn.ReLU(),\n",
        "#             # (128, 22, 22)\n",
        "#             nn.MaxPool2d(2),\n",
        "#             # (128, 11, 11)\n",
        "#             nn.Conv2d(128, 128, 3),\n",
        "#             nn.ReLU(),\n",
        "#             # (128, 8, 8)\n",
        "#             nn.Conv2d(128, 256, 3),\n",
        "#             nn.ReLU(),\n",
        "#             # (256, 6, 6)\n",
        "#             nn.Conv2d(256, 256, 3),\n",
        "#             nn.ReLU(),\n",
        "#             # (256, 4, 4)\n",
        "#             nn.MaxPool2d(2),\n",
        "#             # (256, 2, 2)\n",
        "#             nn.Flatten(),\n",
        "#             # 1024\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(1024, 256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.Linear(256, env.single_action_space.n)\n",
        "#             # 12 possible actions\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.network(x / 255.0)\n",
        "\n",
        "\n",
        "# def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
        "#     slope = (end_e - start_e) / duration\n",
        "#     return max(slope * t + start_e, end_e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KbPbg5G8_sO"
      },
      "source": [
        "### training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I0yXM_e1TGkf"
      },
      "outputs": [],
      "source": [
        "def train(args, trial=None):\n",
        "  try:\n",
        "    run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
        "    prefix = \"\"\n",
        "    if trial:\n",
        "      run_name += f\"_trial_{trial.number}\"\n",
        "      prefix = f\"trial {trial.number}: \"\n",
        "    if args.track:\n",
        "        import wandb\n",
        "\n",
        "        wandb.init(\n",
        "            project=args.wandb_project_name,\n",
        "            entity=args.wandb_entity,\n",
        "            sync_tensorboard=True,\n",
        "            config=vars(args),\n",
        "            name=run_name,\n",
        "            monitor_gym=True,\n",
        "            save_code=True,\n",
        "        )\n",
        "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
        "    writer.add_text(\n",
        "        \"hyperparameters\",\n",
        "        \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
        "    )\n",
        "\n",
        "    # TRY NOT TO MODIFY: seeding\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.backends.cudnn.deterministic = args.torch_deterministic\n",
        "\n",
        "    device_name = \"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\"\n",
        "    device_name = \"mps\" if torch.backends.mps.is_available() and args.mps else device_name\n",
        "    device = torch.device(device_name)\n",
        "\n",
        "    # env setup\n",
        "    env_fns = [make_env(args.env_id, args.seed, i, args.capture_video, run_name, args.video_frequency) for i in range(args.env_cnt)]\n",
        "    envs = gym.vector.SyncVectorEnv(env_fns)\n",
        "    assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n",
        "\n",
        "    q_network = args.QNetwork(envs.single_action_space.n).to(device)\n",
        "    optimizer = optim.Adam(q_network.parameters(), lr=args.learning_rate)\n",
        "    target_network = args.QNetwork(envs.single_action_space.n).to(device)\n",
        "    target_network.load_state_dict(q_network.state_dict())\n",
        "\n",
        "    #summary(q_network, input_size=(1, 84, 84), batch_size=args.batch_size, device=device_name)\n",
        "\n",
        "    rb = ReplayBuffer(\n",
        "        args.buffer_size,\n",
        "        envs.single_observation_space,\n",
        "        envs.single_action_space,\n",
        "        device,\n",
        "        n_envs=args.env_cnt,\n",
        "        optimize_memory_usage=False,\n",
        "        handle_timeout_termination=True,\n",
        "    )\n",
        "    start_time = time.time()\n",
        "    eval_idx = 1\n",
        "\n",
        "    # TRY NOT TO MODIFY: start the game\n",
        "    obs = envs.reset()\n",
        "    for global_step in range(args.total_timesteps):\n",
        "        # ALGO LOGIC: put action logic here\n",
        "        epsilon = linear_schedule(args.start_e, args.end_e, args.exploration_fraction * args.total_timesteps, global_step)\n",
        "        if random.random() < epsilon:\n",
        "            actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
        "        else:\n",
        "            q_values = q_network(torch.Tensor(obs).to(device))\n",
        "            actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
        "\n",
        "        # TRY NOT TO MODIFY: execute the game and log data.\n",
        "        next_obs, rewards, dones, infos = envs.step(actions)\n",
        "\n",
        "        # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
        "        for info in infos:\n",
        "            if \"episode\" in info.keys():\n",
        "                print(f\"{prefix}global_step={global_step}, episodic_return={info['episode']['r']}\")\n",
        "                writer.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n",
        "                writer.add_scalar(\"charts/episodic_length\", info[\"episode\"][\"l\"], global_step)\n",
        "                writer.add_scalar(\"charts/epsilon\", epsilon, global_step)\n",
        "\n",
        "\n",
        "            # Evaluate and report the agent periodically\n",
        "            if trial and global_step % args.eval_frequency == 0 and global_step > 0:\n",
        "                episodic_returns = evaluate(q_network, make_env, args.env_id, args.eval_episodes, f\"{run_name}-eval-{eval_idx}\", args.QNetwork, device, args.eval_epsilon, capture_video=False)\n",
        "                mean_return = np.mean(episodic_returns)\n",
        "                print(f\"{prefix}evaluation_{eval_idx}_mean_return={mean_return}\")\n",
        "                trial.report(mean_return, global_step)\n",
        "                eval_idx += 1\n",
        "\n",
        "                # Check if the trial should be pruned\n",
        "                if trial and trial.should_prune():\n",
        "                    raise optuna.exceptions.TrialPruned()\n",
        "                break\n",
        "\n",
        "        # TRY NOT TO MODIFY: save data to reply buffer; handle `terminal_observation`\n",
        "        real_next_obs = next_obs.copy()\n",
        "        #for idx, d in enumerate(dones):\n",
        "            #if d:\n",
        "                #real_next_obs[idx] = infos[idx][\"terminal_observation\"]  //Tetris environment does not set a terminal observation.\n",
        "        rb.add(obs, real_next_obs, actions, rewards, dones, infos)\n",
        "\n",
        "        # TRY NOT TO MODIFY: CRUCIAL step easy to overlook\n",
        "        obs = next_obs\n",
        "\n",
        "        # ALGO LOGIC: training.\n",
        "        if global_step > args.learning_starts:\n",
        "            if global_step % args.train_frequency == 0:\n",
        "                data = rb.sample(args.batch_size)\n",
        "                with torch.no_grad():\n",
        "                    target_max, _ = target_network(data.next_observations).max(dim=1)\n",
        "                    td_target = data.rewards.flatten() + args.gamma * target_max * (1 - data.dones.flatten())\n",
        "                old_val = q_network(data.observations).gather(1, data.actions).squeeze()\n",
        "                loss = F.mse_loss(td_target, old_val)\n",
        "\n",
        "                if global_step % 100 == 0:\n",
        "                    writer.add_scalar(\"losses/td_loss\", loss, global_step)\n",
        "                    writer.add_scalar(\"losses/q_values\", old_val.mean().item(), global_step)\n",
        "                    # print(\"SPS:\", int(global_step / (time.time() - start_time)))    # steps per second\n",
        "                    writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
        "\n",
        "                # optimize the model\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # update target network\n",
        "            if global_step % args.target_network_frequency == 0:\n",
        "                for target_network_param, q_network_param in zip(target_network.parameters(), q_network.parameters()):\n",
        "                    target_network_param.data.copy_(\n",
        "                        args.tau * q_network_param.data + (1.0 - args.tau) * target_network_param.data\n",
        "                    )\n",
        "\n",
        "    if args.save_model:\n",
        "        model_path = f\"runs/{run_name}/{args.exp_name}.cleanrl_model\"\n",
        "        torch.save(q_network.state_dict(), model_path)\n",
        "        print(f\"{prefix}model saved to {model_path}\")\n",
        "\n",
        "        episodic_returns = evaluate(\n",
        "            model_path,\n",
        "            make_env,\n",
        "            args.env_id,\n",
        "            args.eval_episodes,\n",
        "            run_name=f\"{run_name}-eval-{eval_idx}\",\n",
        "            Model=args.QNetwork,\n",
        "            device=device,\n",
        "            epsilon=args.eval_epsilon,\n",
        "            capture_video=args.capture_video\n",
        "        )\n",
        "        if trial:\n",
        "          mean_return = np.mean(episodic_returns)\n",
        "          print(f\"{prefix}evaluation_{eval_idx}_mean_return={mean_return}\")\n",
        "          trial.set_user_attr(\"mean_return\", float(mean_return))\n",
        "        for idx, episodic_return in enumerate(episodic_returns):\n",
        "            writer.add_scalar(\"eval/episodic_return\", episodic_return, idx)\n",
        "\n",
        "        if args.upload_model:\n",
        "            pass\n",
        "            from cleanrl_utils.huggingface import push_to_hub\n",
        "\n",
        "            repo_name = f\"{args.env_id}-{args.exp_name}-seed{args.seed}\"\n",
        "            repo_id = f\"{args.hf_entity}/{repo_name}\" if args.hf_entity else repo_name\n",
        "            push_to_hub(args, episodic_returns, repo_id, \"DQN\", f\"runs/{run_name}\", f\"videos/{run_name}-eval\")\n",
        "  except:\n",
        "    raise\n",
        "  finally:\n",
        "    envs.close()\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZCEBIoO8pd9D"
      },
      "outputs": [],
      "source": [
        "def make_env(env_id, seed, idx, capture_video, run_name, video_freq=100):\n",
        "    def thunk():\n",
        "        env = gym_tetris.make(env_id)\n",
        "        env = JoypadSpace(env, MOVEMENT)\n",
        "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "        if capture_video:\n",
        "            if idx == 0:\n",
        "                env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\", episode_trigger=lambda ep_num: ep_num % video_freq == 0)\n",
        "        #env = NoopResetEnv(env, noop_max=30)\n",
        "        #env = MaxAndSkipEnv(env, skip=4)\n",
        "        #env = EpisodicLifeEnv(env)\n",
        "        #env = ClipRewardEnv(env)\n",
        "        env = gym.wrappers.ResizeObservation(env, (84, 84))\n",
        "        env = gym.wrappers.GrayScaleObservation(env)\n",
        "        env = gym.wrappers.FrameStack(env, 1)\n",
        "        env.seed(seed)\n",
        "        env.action_space.seed(seed)\n",
        "        env.observation_space.seed(seed)\n",
        "        return env\n",
        "\n",
        "    return thunk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n2UgLd8i0n2"
      },
      "source": [
        "### Cleanrl utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lUe8keIDizOx"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Union\n",
        "\n",
        "def evaluate(\n",
        "    model_input: Union[str, torch.nn.Module],\n",
        "    make_env: Callable,\n",
        "    env_id: str,\n",
        "    eval_episodes: int,\n",
        "    run_name: str,\n",
        "    Model: torch.nn.Module,\n",
        "    device: torch.device = torch.device(\"cpu\"),\n",
        "    epsilon: float = 0.05,\n",
        "    capture_video: bool = True,\n",
        "):\n",
        "    env_fns = [make_env(args.env_id, args.seed, i, args.capture_video, run_name, args.video_frequency) for i in range(args.env_cnt)]\n",
        "    envs = gym.vector.SyncVectorEnv(env_fns)\n",
        "    if isinstance(model_input, str):\n",
        "        model = Model(envs.single_action_space.n).to(device)\n",
        "        model.load_state_dict(torch.load(model_input, map_location=device))\n",
        "    elif isinstance(model_input, torch.nn.Module):\n",
        "        model = model_input\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model_input. It should be either a path (str) or a model instance (torch.nn.Module).\")\n",
        "    model.eval()\n",
        "\n",
        "    obs = envs.reset()\n",
        "    episodic_returns = []\n",
        "    while len(episodic_returns) < eval_episodes:\n",
        "        #if random.random() < epsilon:\n",
        "            #actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
        "        #else:\n",
        "        q_values = model(torch.Tensor(obs).to(device))\n",
        "        actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
        "        next_obs, _, _, infos = envs.step(actions)\n",
        "        for info in infos:\n",
        "            if \"episode\" in info.keys():\n",
        "                print(f\"eval_episode={len(episodic_returns)}, episodic_return={info['episode']['r']}\")\n",
        "                episodic_returns += [info[\"episode\"][\"r\"]]\n",
        "        obs = next_obs\n",
        "    envs.close()\n",
        "    return episodic_returns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhHGXzJGi-yI"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M26LSBq7UOv2"
      },
      "outputs": [],
      "source": [
        "# # Short Run\n",
        "# class Args:\n",
        "#     def __init__(self):\n",
        "#         self.env_id = \"TetrisA-v0\"\n",
        "#         self.exp_name = \"dqn\"\n",
        "#         self.seed = 1\n",
        "#         self.torch_deterministic = True\n",
        "#         self.cuda = True\n",
        "#         self.mps = False\n",
        "#         self.track = False\n",
        "#         self.wandb_project_name = \"cleanRL\"\n",
        "#         self.wandb_entity = None\n",
        "#         self.capture_video = True\n",
        "#         self.save_model = True\n",
        "#         self.upload_model = False\n",
        "#         self.hf_entity = \"\"\n",
        "#         self.total_timesteps = 20000\n",
        "#         self.video_frequency = 100\n",
        "#         self.env_cnt = 2\n",
        "\n",
        "#         # evaluations\n",
        "#         self.total_evaluations = 2\n",
        "#         self.eval_episodes = 4\n",
        "#         self.eval_frequency = int(self.total_timesteps / self.total_evaluations)\n",
        "#         self.eval_epsilon = 0.05\n",
        "\n",
        "#         # Trainable hyperparameters\n",
        "#         self.QNetwork = None\n",
        "#         self.learning_rate = None\n",
        "#         self.buffer_size = None\n",
        "#         self.gamma = None\n",
        "#         self.tau = None\n",
        "#         self.target_network_frequency = None\n",
        "#         self.batch_size = None\n",
        "#         self.start_e = None\n",
        "#         self.end_e = None\n",
        "#         self.exploration_fraction = None\n",
        "#         self.learning_starts = None\n",
        "#         self.train_frequency = None\n",
        "\n",
        "# args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a74aYTyfXD3A"
      },
      "outputs": [],
      "source": [
        "#Weeklong args\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.exp_name = \"Tetris_DQN\"\n",
        "        self.seed = 1\n",
        "        self.torch_deterministic = True\n",
        "        self.cuda = False\n",
        "        self.mps = True\n",
        "        self.track = False\n",
        "        self.wandb_project_name = \"cleanRL\"\n",
        "        self.wandb_entity = None\n",
        "        self.capture_video = True\n",
        "        self.save_model = True\n",
        "        self.upload_model = False\n",
        "        self.hf_entity = \"\"\n",
        "        self.env_id = \"TetrisA-v4\"\n",
        "        self.total_timesteps = 100000\n",
        "        self.learning_rate = 1e-4\n",
        "        self.buffer_size = 100000\n",
        "        self.gamma = 0.99\n",
        "        self.tau = 1.0\n",
        "        self.target_network_frequency = 1000\n",
        "        self.batch_size = 32\n",
        "        self.start_e = 1\n",
        "        self.end_e = 0.01\n",
        "        self.exploration_fraction = 0.10\n",
        "        self.learning_starts = 50000\n",
        "        self.train_frequency = 4\n",
        "        self.video_frequency = 10\n",
        "        self.env_cnt = 1\n",
        "        self.QNetwork = get_model_class(\"tiny\")\n",
        "\n",
        "        # evaluations\n",
        "        self.total_evaluations = 2\n",
        "        self.eval_episodes = 4\n",
        "        self.eval_frequency = int(self.total_timesteps / self.total_evaluations)\n",
        "        self.eval_epsilon = 0.05\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm_lId5hUjDm",
        "outputId": "c886e297-b83f-465d-bba7-06f47371cb71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global_step=6240, episodic_return=-43.0\n",
            "global_step=15034, episodic_return=62.0\n",
            "global_step=21220, episodic_return=-168.0\n",
            "global_step=27192, episodic_return=79.0\n",
            "global_step=34031, episodic_return=-81.0\n",
            "global_step=43414, episodic_return=164.0\n",
            "global_step=48984, episodic_return=-73.0\n",
            "global_step=59084, episodic_return=-126.0\n",
            "global_step=68264, episodic_return=152.0\n",
            "global_step=75318, episodic_return=95.0\n",
            "global_step=80150, episodic_return=-76.0\n",
            "global_step=83438, episodic_return=48.0\n",
            "global_step=86423, episodic_return=-78.0\n",
            "global_step=91217, episodic_return=74.0\n",
            "global_step=95506, episodic_return=-122.0\n",
            "model saved to runs/TetrisA-v4__Tetris_DQN__1__1680808246/Tetris_DQN.cleanrl_model\n",
            "eval_episode=0, episodic_return=26.0\n",
            "eval_episode=1, episodic_return=-1.0\n",
            "eval_episode=2, episodic_return=-7.0\n",
            "eval_episode=3, episodic_return=7.0\n",
            "eval_episode=4, episodic_return=-8.0\n",
            "eval_episode=5, episodic_return=14.0\n",
            "eval_episode=6, episodic_return=-3.0\n",
            "eval_episode=7, episodic_return=-11.0\n",
            "eval_episode=8, episodic_return=21.0\n",
            "eval_episode=9, episodic_return=-18.0\n"
          ]
        }
      ],
      "source": [
        "train(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feANY7_C43d9"
      },
      "source": [
        "## Optuna Hyperparameters Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOrR3bdr6SWT"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy8Tuul96eq2"
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 100  # Maximum number of trials\n",
        "N_JOBS = 2 # Number of jobs to run in parallel\n",
        "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
        "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
        "# N_TIMESTEPS = int(2e4)  # Training budget\n",
        "# EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
        "# N_EVAL_ENVS = 5\n",
        "# N_EVAL_EPISODES = 10\n",
        "TIMEOUT = int(60 * 15)  # 15 minutes\n",
        "\n",
        "#ENV_ID = \"TetrisA-v0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eVBzaoSuj2q"
      },
      "outputs": [],
      "source": [
        "def sample_params(trial: optuna.Trial) -> dict:\n",
        "    params = {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True),\n",
        "        \"buffer_size\": trial.suggest_int(\"buffer_size\", 1000, 5000),\n",
        "        \"gamma\": 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True),\n",
        "        \"tau\": 1.0 - trial.suggest_float(\"tau\", 0.00001, 0.1, log=True),\n",
        "        \"target_network_frequency\": trial.suggest_int(\"target_network_frequency\", 50, 500),\n",
        "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128]),\n",
        "        \"start_e\": trial.suggest_float(\"start_e\", 0.8, 1.0),\n",
        "        \"end_e\": trial.suggest_float(\"end_e\", 0.001, 0.1),\n",
        "        \"exploration_fraction\": trial.suggest_float(\"exploration_fraction\", 0.1, 0.9),\n",
        "        \"learning_starts\": trial.suggest_int(\"learning_starts\", 1000, 5000),\n",
        "        \"train_frequency\": trial.suggest_int(\"train_frequency\", 1, 10),\n",
        "        \"QNetwork\": get_model_class(trial.suggest_categorical(\"model_size\", [\"tiny\", \"small\", \"original\"]))\n",
        "    }\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2qhmpKfpc3p"
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial):\n",
        "    args = Args()\n",
        "    hyperparameters = sample_params(trial)\n",
        "    for key, value in hyperparameters.items():\n",
        "        setattr(args, key, value)\n",
        "\n",
        "    nan_encountered = False\n",
        "    try:\n",
        "      train(args, trial)\n",
        "    except AssertionError as e:\n",
        "      # Sometimes, random hyperparams can generate NaN\n",
        "      print(e)\n",
        "      nan_encountered = True\n",
        "    except optuna.exceptions.TrialPruned:\n",
        "      raise\n",
        "\n",
        "    # Tell the optimizer that the trial failed\n",
        "    if nan_encountered:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    return trial.user_attrs[\"mean_return\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG2JPF25tjlR"
      },
      "outputs": [],
      "source": [
        "study_name = f\"{args.env_id}-{args.exp_name}-test\"\n",
        "study_num = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "06doOr1-oreV",
        "outputId": "521404ab-fec8-45fe-9b72-48dd862c3720"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-04 18:48:05,096]\u001b[0m A new study created in RDB with name: TetrisA-v0-dqn-test-4\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:41: UserWarning:\n",
            "\n",
            "\u001b[33mWARN: Overwriting existing videos at /content/videos/TetrisA-v0__dqn__1__1680634085_trial_1 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:41: UserWarning:\n",
            "\n",
            "\u001b[33mWARN: Overwriting existing videos at /content/videos/TetrisA-v0__dqn__1__1680634085_trial_0 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [16, 32, 20, 20]           2,080\n",
            "              ReLU-2           [16, 32, 20, 20]               0\n",
            "            Conv2d-3             [16, 64, 9, 9]          32,832\n",
            "              ReLU-4             [16, 64, 9, 9]               0\n",
            "            Conv2d-5             [16, 64, 7, 7]          36,928\n",
            "              ReLU-6             [16, 64, 7, 7]               0\n",
            "           Flatten-7                 [16, 3136]               0\n",
            "           Dropout-8                 [16, 3136]               0\n",
            "            Linear-9                  [16, 512]       1,606,144\n",
            "          Dropout-10                  [16, 512]               0\n",
            "             ReLU-11                  [16, 512]               0\n",
            "           Linear-12                   [16, 12]           6,156\n",
            "================================================================\n",
            "Total params: 1,684,140\n",
            "Trainable params: 1,684,140\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.43\n",
            "Forward/backward pass size (MB): 6.11\n",
            "Params size (MB): 6.42\n",
            "Estimated Total Size (MB): 12.97\n",
            "----------------------------------------------------------------\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [32, 32, 20, 20]           2,080\n",
            "              ReLU-2           [32, 32, 20, 20]               0\n",
            "            Conv2d-3             [32, 64, 9, 9]          32,832\n",
            "              ReLU-4             [32, 64, 9, 9]               0\n",
            "            Conv2d-5             [32, 64, 7, 7]          36,928\n",
            "              ReLU-6             [32, 64, 7, 7]               0\n",
            "           Flatten-7                 [32, 3136]               0\n",
            "           Dropout-8                 [32, 3136]               0\n",
            "            Linear-9                  [32, 512]       1,606,144\n",
            "          Dropout-10                  [32, 512]               0\n",
            "             ReLU-11                  [32, 512]               0\n",
            "           Linear-12                   [32, 12]           6,156\n",
            "================================================================\n",
            "Total params: 1,684,140\n",
            "Trainable params: 1,684,140\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.86\n",
            "Forward/backward pass size (MB): 12.22\n",
            "Params size (MB): 6.42\n",
            "Estimated Total Size (MB): 19.51\n",
            "----------------------------------------------------------------\n",
            "global_step=4713, episodic_return=8.0\n",
            "global_step=4727, episodic_return=11.0\n",
            "global_step=5695, episodic_return=30.0\n",
            "global_step=5758, episodic_return=48.0\n",
            "global_step=5963, episodic_return=2.0\n",
            "global_step=6650, episodic_return=50.0\n",
            "global_step=6754, episodic_return=43.0\n",
            "global_step=7496, episodic_return=39.0\n",
            "global_step=7655, episodic_return=60.0\n",
            "global_step=8372, episodic_return=53.0\n",
            "global_step=9163, episodic_return=91.0\n",
            "global_step=9864, episodic_return=82.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:41: UserWarning:\n",
            "\n",
            "\u001b[33mWARN: Overwriting existing videos at /content/videos/TetrisA-v0__dqn__1__1680634085_trial_0-eval-1 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:41: UserWarning:\n",
            "\n",
            "\u001b[33mWARN: Overwriting existing videos at /content/videos/TetrisA-v0__dqn__1__1680634085_trial_1-eval-1 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval_episode=0, episodic_return=13.0\n",
            "eval_episode=1, episodic_return=13.0\n",
            "eval_episode=0, episodic_return=0.0\n",
            "eval_episode=1, episodic_return=0.0\n",
            "eval_episode=2, episodic_return=2.0\n",
            "eval_episode=3, episodic_return=2.0\n",
            "evaluation_1_mean_return=1.0\n",
            "eval_episode=2, episodic_return=10.0\n",
            "eval_episode=3, episodic_return=10.0\n",
            "evaluation_1_mean_return=11.5\n",
            "global_step=10030, episodic_return=0.0\n",
            "global_step=12051, episodic_return=71.0\n",
            "global_step=12474, episodic_return=34.0\n",
            "global_step=11408, episodic_return=22.0\n",
            "global_step=11602, episodic_return=31.0\n",
            "global_step=12441, episodic_return=23.0\n",
            "global_step=13057, episodic_return=56.0\n",
            "global_step=13537, episodic_return=83.0\n",
            "global_step=15321, episodic_return=75.0\n",
            "global_step=14215, episodic_return=67.0\n",
            "global_step=16320, episodic_return=39.0\n",
            "global_step=15420, episodic_return=89.0\n",
            "global_step=16655, episodic_return=24.0\n",
            "global_step=15561, episodic_return=86.0\n",
            "global_step=16358, episodic_return=53.0\n",
            "global_step=17826, episodic_return=46.0\n",
            "global_step=16628, episodic_return=68.0\n",
            "global_step=17612, episodic_return=67.0\n",
            "global_step=18834, episodic_return=102.0\n",
            "global_step=18082, episodic_return=77.0\n",
            "global_step=19599, episodic_return=53.0\n",
            "global_step=18725, episodic_return=44.0\n",
            "model saved to runs/TetrisA-v0__dqn__1__1680634085_trial_0/dqn.cleanrl_model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:41: UserWarning:\n",
            "\n",
            "\u001b[33mWARN: Overwriting existing videos at /content/videos/TetrisA-v0__dqn__1__1680634085_trial_0-eval-2 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "global_step=19382, episodic_return=58.0\n",
            "model saved to runs/TetrisA-v0__dqn__1__1680634085_trial_1/dqn.cleanrl_model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:41: UserWarning:\n",
            "\n",
            "\u001b[33mWARN: Overwriting existing videos at /content/videos/TetrisA-v0__dqn__1__1680634085_trial_1-eval-2 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval_episode=0, episodic_return=20.0\n",
            "eval_episode=1, episodic_return=12.0\n",
            "eval_episode=0, episodic_return=82.0\n",
            "eval_episode=1, episodic_return=82.0\n",
            "eval_episode=2, episodic_return=18.0\n",
            "eval_episode=2, episodic_return=47.0\n",
            "eval_episode=3, episodic_return=47.0\n",
            "evaluation_2_mean_return=64.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-04 18:58:43,029]\u001b[0m Trial 0 finished with value: 64.5 and parameters: {'learning_rate': 0.0005280306275006966, 'buffer_size': 3200, 'gamma': 0.08173960145792994, 'tau': 0.0070037505605310855, 'target_network_frequency': 394, 'batch_size': 32, 'start_e': 0.9418616805831531, 'end_e': 0.07026631202936463, 'exploration_fraction': 0.2786340498222212, 'learning_starts': 2759, 'train_frequency': 5, 'model_size': 'original'}. Best is trial 0 with value: 64.5.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval_episode=3, episodic_return=20.0\n",
            "evaluation_2_mean_return=17.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-04 18:58:43,731]\u001b[0m Trial 1 finished with value: 17.5 and parameters: {'learning_rate': 0.0001930906083966729, 'buffer_size': 3694, 'gamma': 0.0005952157816468894, 'tau': 0.0043257038165043565, 'target_network_frequency': 458, 'batch_size': 16, 'start_e': 0.860306969639063, 'end_e': 0.034634846117706126, 'exploration_fraction': 0.6796527795801472, 'learning_starts': 3083, 'train_frequency': 9, 'model_size': 'original'}. Best is trial 0 with value: 64.5.\u001b[0m\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:41: UserWarning:\n",
            "\n",
            "\u001b[33mWARN: Overwriting existing videos at /content/videos/TetrisA-v0__dqn__1__1680634723_trial_2 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [64, 64, 26, 26]           3,200\n",
            "              ReLU-2           [64, 64, 26, 26]               0\n",
            "            Conv2d-3          [64, 128, 22, 22]         204,928\n",
            "              ReLU-4          [64, 128, 22, 22]               0\n",
            "         MaxPool2d-5          [64, 128, 11, 11]               0\n",
            "            Conv2d-6            [64, 128, 9, 9]         147,584\n",
            "              ReLU-7            [64, 128, 9, 9]               0\n",
            "            Conv2d-8            [64, 256, 7, 7]         295,168\n",
            "              ReLU-9            [64, 256, 7, 7]               0\n",
            "           Conv2d-10            [64, 256, 5, 5]         590,080\n",
            "             ReLU-11            [64, 256, 5, 5]               0\n",
            "        MaxPool2d-12            [64, 256, 2, 2]               0\n",
            "          Flatten-13                 [64, 1024]               0\n",
            "          Dropout-14                 [64, 1024]               0\n",
            "           Linear-15                  [64, 256]         262,400\n",
            "             ReLU-16                  [64, 256]               0\n",
            "          Dropout-17                  [64, 256]               0\n",
            "           Linear-18                   [64, 12]           3,084\n",
            "================================================================\n",
            "Total params: 1,506,444\n",
            "Trainable params: 1,506,444\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.72\n",
            "Forward/backward pass size (MB): 140.82\n",
            "Params size (MB): 5.75\n",
            "Estimated Total Size (MB): 148.29\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/record_video.py:41: UserWarning:\n",
            "\n",
            "\u001b[33mWARN: Overwriting existing videos at /content/videos/TetrisA-v0__dqn__1__1680634723_trial_3 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [64, 64, 26, 26]           3,200\n",
            "              ReLU-2           [64, 64, 26, 26]               0\n",
            "            Conv2d-3          [64, 128, 22, 22]         204,928\n",
            "              ReLU-4          [64, 128, 22, 22]               0\n",
            "         MaxPool2d-5          [64, 128, 11, 11]               0\n",
            "            Conv2d-6            [64, 128, 9, 9]         147,584\n",
            "              ReLU-7            [64, 128, 9, 9]               0\n",
            "            Conv2d-8            [64, 256, 7, 7]         295,168\n",
            "              ReLU-9            [64, 256, 7, 7]               0\n",
            "           Conv2d-10            [64, 256, 5, 5]         590,080\n",
            "             ReLU-11            [64, 256, 5, 5]               0\n",
            "        MaxPool2d-12            [64, 256, 2, 2]               0\n",
            "          Flatten-13                 [64, 1024]               0\n",
            "          Dropout-14                 [64, 1024]               0\n",
            "           Linear-15                  [64, 256]         262,400\n",
            "             ReLU-16                  [64, 256]               0\n",
            "          Dropout-17                  [64, 256]               0\n",
            "           Linear-18                   [64, 12]           3,084\n",
            "================================================================\n",
            "Total params: 1,506,444\n",
            "Trainable params: 1,506,444\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.72\n",
            "Forward/backward pass size (MB): 140.82\n",
            "Params size (MB): 5.75\n",
            "Estimated Total Size (MB): 148.29\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m[W 2023-04-04 18:59:54,822]\u001b[0m Trial 3 failed with parameters: {'learning_rate': 6.855805285103662e-05, 'buffer_size': 4754, 'gamma': 0.0025302609190156044, 'tau': 0.04331334839644418, 'target_network_frequency': 422, 'batch_size': 64, 'start_e': 0.8422605019439453, 'end_e': 0.006240097722642429, 'exploration_fraction': 0.2677176069418209, 'learning_starts': 4632, 'train_frequency': 8, 'model_size': 'small'} because of the following error: RuntimeError('CUDA error: an illegal memory access was encountered\\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\\n').\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-15-944ff10dd6ac>\", line 9, in objective\n",
            "    train(args, trial)\n",
            "  File \"<ipython-input-18-47feb1bc2e82>\", line 66, in train\n",
            "    actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
            "RuntimeError: CUDA error: an illegal memory access was encountered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\u001b[33m[W 2023-04-04 18:59:54,826]\u001b[0m Trial 3 failed with value None.\u001b[0m\n",
            "\u001b[33m[W 2023-04-04 18:59:54,839]\u001b[0m Trial 2 failed with parameters: {'learning_rate': 4.441159485251018e-05, 'buffer_size': 2954, 'gamma': 0.0006381212449541604, 'tau': 0.00013290592688321339, 'target_network_frequency': 257, 'batch_size': 64, 'start_e': 0.8683914143302339, 'end_e': 0.011492954992381413, 'exploration_fraction': 0.46911005272538175, 'learning_starts': 4433, 'train_frequency': 9, 'model_size': 'small'} because of the following error: RuntimeError('CUDA error: an illegal memory access was encountered\\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\\n').\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-15-944ff10dd6ac>\", line 9, in objective\n",
            "    train(args, trial)\n",
            "  File \"<ipython-input-18-47feb1bc2e82>\", line 65, in train\n",
            "    q_values = q_network(torch.Tensor(obs).to(device))\n",
            "RuntimeError: CUDA error: an illegal memory access was encountered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\u001b[33m[W 2023-04-04 18:59:54,840]\u001b[0m Trial 2 failed with value None.\u001b[0m\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d7a7ba2fd859>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mstudy_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_TRIALS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_JOBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    101\u001b[0m                         \u001b[0;31m# Raise if exception occurred in executing the completed futures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     futures.add(\n",
            "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-944ff10dd6ac>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnan_encountered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;31m# Sometimes, random hyperparams can generate NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-47feb1bc2e82>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, trial)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# TRY NOT TO MODIFY: execute the game and log data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "args = Args()\n",
        "\n",
        "# Set pytorch num threads to 1 for faster training\n",
        "torch.set_num_threads(1)\n",
        "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
        "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
        "# Do not prune before 1/3 of the max budget is used\n",
        "pruner = MedianPruner(\n",
        "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=args.total_timesteps // 3\n",
        ")\n",
        "# Create the study and start the hyperparameter optimization\n",
        "study = optuna.create_study(study_name=f\"{study_name}-{study_num}\", storage=\"sqlite:///db.sqlite3\", sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
        "study_num += 1\n",
        "try:\n",
        "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Value: {trial.value}\")\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "print(\"  User attrs:\")\n",
        "for key, value in trial.user_attrs.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# Write report\n",
        "study.trials_dataframe().to_csv(f\"study_results_dqn_{study_name}_{study_num}.csv\")\n",
        "\n",
        "fig1 = plot_optimization_history(study)\n",
        "fig2 = plot_param_importances(study)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q-ZggO-qtbL"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nmdj4k4rg_k",
        "outputId": "e3a77d57-8695-4cec-e510-b14164cc0eb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listening on http://127.0.0.1:8080/\n",
            "Hit Ctrl-C to quit.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/optuna-dashboard\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/optuna_dashboard/_cli.py\", line 128, in main\n",
            "    run_wsgiref(app, args.host, args.port, args.quiet)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/optuna_dashboard/_cli.py\", line 38, in run_wsgiref\n",
            "    httpd = make_server(host, port, app, server_class=ThreadedWSGIServer)\n",
            "  File \"/usr/lib/python3.9/wsgiref/simple_server.py\", line 154, in make_server\n",
            "    server = server_class((host, port), handler_class)\n",
            "  File \"/usr/lib/python3.9/socketserver.py\", line 452, in __init__\n",
            "    self.server_bind()\n",
            "  File \"/usr/lib/python3.9/wsgiref/simple_server.py\", line 50, in server_bind\n",
            "    HTTPServer.server_bind(self)\n",
            "  File \"/usr/lib/python3.9/http/server.py\", line 137, in server_bind\n",
            "    socketserver.TCPServer.server_bind(self)\n",
            "  File \"/usr/lib/python3.9/socketserver.py\", line 466, in server_bind\n",
            "    self.socket.bind(self.server_address)\n",
            "OSError: [Errno 98] Address already in use\n"
          ]
        }
      ],
      "source": [
        "!optuna-dashboard sqlite:///db.sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4bx38z9qxTo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "W1KbrN9Li5i8",
        "ORRWWz8dIqaH"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tetrisenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "4a7f40d72114c62e91de8d79ab05a4f10d2c48422b550572d6072f074507511d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
